{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Programming Seating Arrangement Script "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import math\n",
    "start_time = time.time()\n",
    "\n",
    "EventID = 221\n",
    "\n",
    "# Which machine are you accessing from?\n",
    "EC2_access = True\n",
    "parallels_access =    False\n",
    "\n",
    "\n",
    "# Do you want to run the models or bring them in from the past runs? - True means run them \n",
    "run_models = False  \n",
    "\n",
    "# EC2_access = True\n",
    "# parallels_access = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sessions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This session is \n",
    "lunch_session =  8 \n",
    "# Manager and allocator only sessions - matching on \n",
    "MAonly_session = 4 \n",
    "dive_deeper_sessions = [] \n",
    "# The classic logic \n",
    "main_sessions = [1,2,3,5,6,7,8] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which linear progamming API am I using? \n",
    "gurobi_lp = True\n",
    "\n",
    "\n",
    "# Pairs cannot sit together more than this number of times in the MAIN sessions \n",
    "upper_count_pair_counts = 1\n",
    "\n",
    "\n",
    "# Variables for event \n",
    "number_sessions =  8 \n",
    "max_table_size_dict  = {1:9, 2:9, 3:9, 4:9, 5:9, 6:9, 7:9, 8:10}\n",
    "max_number_tables = 21\n",
    "\n",
    "\n",
    "# When this is true the scheduling conflicts are included, \n",
    "# if changed to false they are removed and everyone is included \n",
    "scheduling_conflicts_on = True\n",
    "\n",
    "\n",
    "# Reporting Outputs \n",
    "write_to_DB = False \n",
    "write_to_excel = True\n",
    "\n",
    "cancelled_contacts = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical and Data Manipulation\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import math\n",
    "import statistics\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Functional Programming\n",
    "from functools import reduce \n",
    "import json \n",
    "import pickle \n",
    "\n",
    "# Copying and Randomization\n",
    "import copy\n",
    "import random\n",
    "\n",
    "# Iteration and Combinations\n",
    "import itertools\n",
    "from itertools import repeat, combinations, permutations, combinations_with_replacement\n",
    "\n",
    "# Collections\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# Excel and Data Handling\n",
    "import xlsxwriter\n",
    "from openpyxl.utils import get_column_letter\n",
    "\n",
    "# Database Connectivity\n",
    "import pyodbc\n",
    "import sqlalchemy as db\n",
    "from sqlalchemy import create_engine, MetaData, Table, Column, Integer, String\n",
    "\n",
    "# Text Manipulation\n",
    "import re\n",
    "\n",
    "# Date and Time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Progress Bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# String Matching\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# Word Document Manipulation\n",
    "from docx import Document\n",
    "from docx.shared import Cm\n",
    "\n",
    "# Graph Theory\n",
    "import networkx as nx\n",
    "\n",
    "# Linear Programming\n",
    "import pulp\n",
    "from pulp import lpSum, LpMaximize\n",
    "import gurobipy as grb\n",
    "from gurobipy import Model, GRB\n",
    "\n",
    "# System and Process Information\n",
    "import psutil\n",
    "import sys\n",
    "\n",
    "# Excel and Data Handling\n",
    "import xlsxwriter\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(24)\n",
    "\n",
    "# Ignore Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorts the (A) and (F) in the dataframe\n",
    "def sort_group_by_marker(group, session_columns):\n",
    "    # Extract the last 3 characters from each session column\n",
    "    group[session_columns] = group[session_columns].apply(lambda x: x.str[-3:])\n",
    "    \n",
    "    # Create a list of session columns to use for sorting\n",
    "    sort_columns = list(session_columns)\n",
    "    \n",
    "    # Sort the DataFrame by the specified session columns\n",
    "    group = group.sort_values(by=sort_columns, ascending=True)\n",
    "    \n",
    "    # Drop the temporary columns used for sorting\n",
    "    group = group.drop(session_columns, axis=1)\n",
    "    \n",
    "    return group\n",
    "\n",
    "# Print red bold text \n",
    "def print_in_red_and_large(text):\n",
    "    formatted_text = f\"\\033[91m\\033[1m{text}\\033[0m\"\n",
    "    print(formatted_text)\n",
    "\n",
    "\n",
    "# Write a table to the database\n",
    "def create_database_table(table_name, df_name, column_names, engine):\n",
    "    # Create the metadata object\n",
    "    metadata = MetaData()\n",
    "\n",
    "    # Define the table\n",
    "    table = Table(\n",
    "        table_name,\n",
    "        metadata,\n",
    "        Column('ID', Integer, primary_key=True),  # Add an ID column as primary key\n",
    "        *(Column(col, String(255), nullable=False) for col in column_names)\n",
    "    )\n",
    "\n",
    "    # Create the table in the database\n",
    "    metadata.create_all(engine)\n",
    "\n",
    "    # Ensure the table is created\n",
    "    tables = pd.read_sql(\"select * from INFORMATION_SCHEMA.TABLES\", engine)\n",
    "    if table_name in tables['TABLE_NAME'].values:\n",
    "        print(f\"Table '{table_name}' created successfully.\")\n",
    "    else:\n",
    "        print(f\"Error: Table '{table_name}' not found in the database.\")\n",
    "\n",
    "# Changes a name from first_last_A to First Last (A)\n",
    "def convert_name_format(name):\n",
    "    parts = name.split('_')\n",
    "    first_name = parts[0].capitalize()\n",
    "    last_name = parts[1].capitalize()\n",
    "    group = parts[2].upper()\n",
    "    formatted_name = f\"{first_name} {last_name}  ({group})\"\n",
    "    return formatted_name\n",
    "\n",
    "# Define a function to extract the session number\n",
    "def extract_session_number(title):\n",
    "    match = re.search(r'#(\\d+)', title)\n",
    "    if match:\n",
    "        session_number = match.group(1)\n",
    "        return f\"Session {session_number}\"\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OCDB Connection \n",
    "\n",
    "logins_username = \"\"\n",
    "\n",
    "logins_password = \"\"\n",
    "\n",
    "server =  \"\"\n",
    "\n",
    "# Choose Database\n",
    "database= \"\"\n",
    "\n",
    "## Create Engine and Connection to the Database\n",
    "engine = db.create_engine(\n",
    "    'mssql+pyodbc://'+logins_username+':'+logins_password+'@'+server+'/'+database+'?driver=SQL Server', \n",
    "    use_setinputsizes=False) # This argument got rid of the Error\n",
    "\n",
    "cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+server+';DATABASE='+database+';UID='+logins_username+';PWD='+ logins_password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Pull in Fund and Allocator Data to match names for Marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose Database\n",
    "database = \"\"\n",
    "\n",
    "## Create Engine and Connection to the Database\n",
    "engine = db.create_engine(\n",
    "    'mssql+pyodbc://'+logins_username+':'+logins_password+'@'+server+'/'+database+'?driver=SQL Server', \n",
    "    use_setinputsizes=False) # This argument got rid of the Error\n",
    "\n",
    "cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+server+';DATABASE='+database+';UID='+logins_username+';PWD='+ logins_password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  **Pull in the event registrations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### platform/DB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Queries \n",
    "df_database = pd.read_sql('select * from ----', cnxn)\n",
    "\n",
    "df_database['FirstName'] = df_database['FirstName'].str.strip()\n",
    "df_database['LastName'] = df_database['LastName'].str.strip()\n",
    "df_database['Email'] = df_database['Email'].str.lower().str.strip()\n",
    "\n",
    "\n",
    "# Add contact to database to compare\n",
    "condition = df_database['CompanyType'] == 'Fund'\n",
    "df_database.loc[condition, 'Contact'] = df_database.loc[condition, 'FirstName'].str.lower() + '_' + df_database.loc[condition, 'LastName'].str.lower() + \"_F\"\n",
    "\n",
    "condition = df_database['CompanyType'] == 'Investor'\n",
    "df_database.loc[condition, 'Contact'] = df_database.loc[condition, 'FirstName'].str.lower() + '_' + df_database.loc[condition, 'LastName'].str.lower() + \"_A\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### excel reg data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EC2_access == True:\n",
    "       df_excel_fund = pd.read_excel(r\"\", sheet_name = 'Public Managers')\n",
    "       df_excel_allocator = pd.read_excel(r\"\", sheet_name = 'Public Allocators')\n",
    "       df_excel_staff = pd.read_excel(r\"\", sheet_name = 'Staff')\n",
    "if parallels_access == True:\n",
    "       df_excel_fund = pd.read_excel(r\"\", sheet_name = 'Public Managers')\n",
    "       df_excel_allocator = pd.read_excel(r\"\", sheet_name = 'Public Allocators')\n",
    "       df_excel_staff = pd.read_excel(r\"\", sheet_name = 'Staff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Subset to only needed columns\n",
    "df_excel_fund = df_excel_fund[['Email', 'First Name', 'Last Name', '*Role',  'AUM Range', 'Asset Class', 'Sub Asset Clases']]\n",
    "\n",
    "df_excel_allocator = df_excel_allocator[['Email', 'First Name', 'Last Name', '*Role', \n",
    "       '*Description of Organization', 'Manager Size Preference 1',\n",
    "       'Manager Size Preference 2']]\n",
    "\n",
    "# Concat them together \n",
    "df_excel = pd.concat([df_excel_fund, df_excel_allocator], ignore_index=True)\n",
    "\n",
    "# Email is my primary key - fold to lower \n",
    "df_excel['Email'] = df_excel['Email'].str.lower().str.strip()\n",
    "df_excel['First Name'] = df_excel['First Name'].str.strip()\n",
    "df_excel['Last Name'] = df_excel['Last Name'].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there is no role assigned for this guy, make it fund \n",
    "if df_excel.loc[(df_excel['First Name'] == 'George') & (df_excel['Last Name'] == 'Michelakis')]['*Role'].isna().values[0] == True:\n",
    "    df_excel.loc[(df_excel['First Name'] == 'George') & (df_excel['Last Name'] == 'Michelakis'), '*Role'] = 'Manager'\n",
    "\n",
    "if df_excel.loc[(df_excel['First Name'] == 'Cyrus') & (df_excel['Last Name'] == 'Shirzadi')]['*Role'].isna().values[0] == True:\n",
    "    df_excel.loc[(df_excel['First Name'] == 'Cyrus') & (df_excel['Last Name'] == 'Shirzadi'), '*Role'] = 'Manager'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add contact to database to compare\n",
    "condition = df_excel['*Role'] == 'Manager'\n",
    "df_excel.loc[condition, 'Contact'] = df_excel.loc[condition, 'First Name'].str.lower() + '_' + df_excel.loc[condition, 'Last Name'].str.lower() + \"_F\"\n",
    "\n",
    "condition = df_excel['*Role'] == 'Allocator'\n",
    "df_excel.loc[condition, 'Contact'] = df_excel.loc[condition, 'First Name'].str.lower() + '_' + df_excel.loc[condition, 'Last Name'].str.lower() + \"_A\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  remove cancelled people "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel = df_excel[~df_excel['Contact'].isin(cancelled_contacts)]\n",
    "df_database = df_database[~df_database['Contact'].isin(cancelled_contacts)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Create list of facilitators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to just the facilitators\n",
    "df_excel_staff = df_excel_staff[df_excel_staff['Faciliator']=='Y']\n",
    "\n",
    "# Add contact\n",
    "df_excel_staff['Contact'] = df_excel_staff['First Name'].str.strip().str.lower() + '_' + df_excel_staff['Last Name'].str.strip().str.lower() + \"_S\"\n",
    "facilitators = df_excel_staff['Contact'].unique().tolist()\n",
    "\n",
    "if len(facilitators) == 19:\n",
    "    facilitators.append('testing_testing_S')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge database data and excel data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_db = df_database.merge(df_excel, on = 'Contact', how = 'left', suffixes=['_db', '_excel']) \n",
    "\n",
    "\n",
    "# Where one of them is not NA, are they always equal? If there are no rows returned that means yes! \n",
    "if df_db[df_db['AUM Range_excel'].notna() & df_db['AUM Range_db'].notna() & (df_db['AUM Range_db'] != df_db['AUM Range_excel'])][['AUM Range_db', 'AUM Range_excel']].shape[0] >0:\n",
    "    raise ValueError('!!')\n",
    "\n",
    "# because there are a TON more empty values in excel, im using the DB version\n",
    "# df_database['AUM Range'].isna().sum(), df_excel['AUM Range'].isna().sum()\n",
    "df_db =df_db.drop(columns = ['AUM Range_excel', 'Email_excel', 'Email_db']).rename(columns = {'AUM Range_db':'AUM Range'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  update connection - pulling from different database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose Database\n",
    "database = 'FundsForFood-Prod'\n",
    "\n",
    "## Create Engine and Connection to the Database\n",
    "engine = db.create_engine(\n",
    "    'mssql+pyodbc://'+logins_username+':'+logins_password+'@'+server+'/'+database+'?driver=SQL Server', \n",
    "    use_setinputsizes=False) # This argument got rid of the Error\n",
    "\n",
    "cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+server+';DATABASE='+database+';UID='+logins_username+';PWD='+ logins_password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scheduling Conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflicts_query = f'''\n",
    "Select ads.AgendaDaySessionID, ads.Title, adsi.ContactId, adsi.IsDeleted\n",
    "\n",
    "from [FundsForFood-Prod]..AgendaDaySession ads\n",
    "\n",
    "Join [FundsForFood-Prod]..AgendaDaySessionInterest adsi\n",
    "\n",
    "on ads.AgendaDaySessionID  = adsi.AgendaDaySessionID\n",
    "\n",
    "Where EventID = {EventID}\n",
    "\n",
    "and ads.Title like '%Session #%'\n",
    "\n",
    "and adsi.IsDeleted = 0\n",
    "\n",
    "Group by ads.AgendaDaySessionID,ads.Title, adsi.ContactId, adsi.IsDeleted\n",
    "\n",
    "Order by adsi.ContactID asc, ads.Title asc'''\n",
    "\n",
    "\n",
    "scheduling_conflicts_df_db = pd.read_sql(conflicts_query, cnxn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for each contactID I want to add Lunch! \n",
    "- Lunch availability is not collected since it is not considered a \"session\" yet it is to us \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new df with the same columns\n",
    "df = pd.DataFrame(columns = scheduling_conflicts_df_db.columns)\n",
    "df['ContactId'] = scheduling_conflicts_df_db['ContactId'].unique()\n",
    "df['Title'] = 'Session #8: Lunch'\n",
    "df['IsDeleted'] = False\n",
    "df['AgendaDaySessionID'] = 0\n",
    "\n",
    "scheduling_conflicts_df_db = pd.concat([scheduling_conflicts_df_db, df]).sort_values(by = [\"ContactId\", 'Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Close Codf_dbnnection\n",
    "cnxn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Fund and Allocator DB Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into FUnd and allocator df\n",
    "allocator_df_db  =  df_db[df_db['CompanyType'] == 'Investor']\n",
    "fund_df_db  =  df_db[df_db['CompanyType'] == 'Fund']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop columns that are completely null\n",
    "# allocator_data_db = allocator_df_db.dropna(axis='columns', how='all')\n",
    "# fund_data_db = fund_data_db.dropna(axis='columns', how='all')\n",
    "allocator_data_db = allocator_df_db\n",
    "fund_data_db = fund_df_db\n",
    "\n",
    "# Create a contact field \n",
    "fund_data_db['Contact'] = fund_data_db['FirstName'].str.lower() + '_' + fund_data_db['LastName'].str.lower() + '_F'\n",
    "allocator_data_db['Contact'] = allocator_data_db['FirstName'].str.lower() + '_' + allocator_data_db['LastName'].str.lower() + '_A'\n",
    "\n",
    "# Fold first and last name to lower \n",
    "fund_data_db['FirstName'] = fund_data_db['FirstName'].str.lower()\n",
    "fund_data_db['LastName'] = fund_data_db['LastName'].str.lower()\n",
    "\n",
    "fund_data_db['AUM Range'] =fund_data_db['AUM Range'].str.strip()\n",
    "\n",
    "allocator_data_db['FirstName'] = allocator_data_db['FirstName'].str.lower()\n",
    "allocator_data_db['LastName'] = allocator_data_db['LastName'].str.lower()\n",
    "\n",
    "# Rename to match what I have been using in the following code\n",
    "allocator_data_db = allocator_data_db.rename(columns = {'Asset Class 1': 'Asset Class Theme Pref 1','Asset Class 2': 'Asset Class Theme Pref 2' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "metadata": {},
   "outputs": [],
   "source": [
    "allocator_data_db['Preference'] = allocator_data_db['Preference'].fillna('')\n",
    "allocator_data_db['NoPreference'] = allocator_data_db['NoPreference'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_db[~df_db['Contact'].isin(df_excel['Contact'].unique())].shape[0] >1: # changed this to greater than 1 since elaine chan is in there \n",
    "    raise ValueError ('Excel and DB values do not align!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocess preference and no preference names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 975,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace whitespace values with None (null)\n",
    "allocator_data_db.loc[allocator_data_db['Preference'].str.strip() == '', 'Preference'] = None\n",
    "\n",
    "if allocator_data_db['Contact'].nunique() == allocator_data_db.shape[0]:\n",
    "    for contact in allocator_data_db['Contact'].unique():\n",
    "        contact_rows = allocator_data_db['Contact'] == contact\n",
    "        if allocator_data_db.loc[contact_rows, 'Preference'].iloc[0] is not None:\n",
    "            # Get the preference values for the current contact\n",
    "            names_string = allocator_data_db.loc[contact_rows, 'Preference'].iloc[0]\n",
    "            names_list = names_string.split(',')\n",
    "\n",
    "            # Strip whitespace, fold to lowercase, and replace spaces with underscores\n",
    "            cleaned_names_list = [name.strip().lower().replace(' ', '_') + '_F' for name in names_list]\n",
    "\n",
    "            # Update the \"Preference\" column with the formatted names\n",
    "            allocator_data_db.loc[contact_rows, 'Preference'] = ','.join(cleaned_names_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace whitespace values with None (null)\n",
    "allocator_data_db.loc[allocator_data_db['NoPreference'].str.strip() == '', 'NoPreference'] = None\n",
    "\n",
    "if allocator_data_db['Contact'].nunique() == allocator_data_db.shape[0]:\n",
    "    for contact in allocator_data_db['Contact'].unique():\n",
    "        contact_rows = allocator_data_db['Contact'] == contact\n",
    "        if allocator_data_db.loc[contact_rows, 'NoPreference'].iloc[0] is not None:\n",
    "            # Get the preference values for the current contact\n",
    "            names_string = allocator_data_db.loc[contact_rows, 'NoPreference'].iloc[0]\n",
    "            names_list = names_string.split(',')\n",
    "\n",
    "            # Strip whitespace, fold to lowercase, and replace spaces with underscores\n",
    "            cleaned_names_list = [name.strip().lower().replace(' ', '_') + '_F' for name in names_list]\n",
    "\n",
    "            # Update the \"Preference\" column with the formatted names\n",
    "            allocator_data_db.loc[contact_rows, 'NoPreference'] = ','.join(cleaned_names_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "fund_data_db['Preference'] = fund_data_db['Preference'].fillna('')\n",
    "\n",
    "# Replace whitespace values with None (null)\n",
    "fund_data_db.loc[fund_data_db['Preference'].str.strip() == '', 'Preference'] = None\n",
    "\n",
    "if fund_data_db['Contact'].nunique() == fund_data_db.shape[0]:\n",
    "    print('ok')\n",
    "    for contact in fund_data_db['Contact'].unique():\n",
    "        contact_rows = fund_data_db['Contact'] == contact\n",
    "        if fund_data_db.loc[contact_rows, 'Preference'].iloc[0] is not None:\n",
    "            # Get the preference values for the current contact\n",
    "            names_string = fund_data_db.loc[contact_rows, 'Preference'].iloc[0]\n",
    "            names_list = names_string.split(',')\n",
    "\n",
    "            # Strip whitespace, fold to lowercase, and replace spaces with underscores\n",
    "            cleaned_names_list = [name.strip().lower().replace(' ', '_') + '_A' for name in names_list]\n",
    "\n",
    "            # Update the \"Preference\" column with the formatted names\n",
    "            fund_data_db.loc[contact_rows, 'Preference'] = ','.join(cleaned_names_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fold to Lowercase and strip whitespace before merge \n",
    "# fund_data_db['Email']  = fund_data_db['Email'].str.lower().str.strip()\n",
    "# allocator_data_db['Email']  = allocator_data_db['Email'].str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "metadata": {},
   "outputs": [],
   "source": [
    "allocator_data_db['NoPreference'] = allocator_data_db['NoPreference'].str.replace('__', '_')\n",
    "allocator_data_db['Preference'] = allocator_data_db['Preference'].str.replace('__', '_')\n",
    "\n",
    "fund_data_db['NoPreference'] = fund_data_db['NoPreference'].str.replace('__', '_')\n",
    "fund_data_db['Preference'] = fund_data_db['Preference'].str.replace('__', '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Remove Cancelled Contacts from prefrences*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in cancelled_contacts:\n",
    "    if name.endswith('_F'):\n",
    "        allocator_data_db['Preference'] = allocator_data_db['Preference'].str.replace(name, '')\n",
    "        allocator_data_db['Preference'] = allocator_data_db['Preference'].str.replace(',,', ',')\n",
    "\n",
    "        allocator_data_db['NoPreference'] = allocator_data_db['NoPreference'].str.replace(name, '')\n",
    "        allocator_data_db['NoPreference'] = allocator_data_db['NoPreference'].str.replace(',,', ',')\n",
    "    elif name.endswith('_A'):\n",
    "        fund_data_db['Preference'] = fund_data_db['Preference'].str.replace(name, '')\n",
    "        fund_data_db['Preference'] = fund_data_db['Preference'].str.replace(',,', ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scheduling Conflicts DB Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocessing Scheduling conflicts data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 983,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# are there any contactID values used for funds and allocators?\n",
    "\n",
    "set(fund_df_db['ContactID'].unique()).intersection(set(allocator_df_db['ContactID'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scheduling_conflicts_on:\n",
    "    # list of funds and allocators\n",
    "    fund_and_allocator_contacts = list(set(fund_df_db['ContactID'].unique()) | set(allocator_df_db['ContactID'].unique()))\n",
    "\n",
    "    # Filter down to only contacts that are relevant\n",
    "    scheduling_conflicts_df = scheduling_conflicts_df_db[scheduling_conflicts_df_db['ContactId'].isin(fund_and_allocator_contacts)]\n",
    "\n",
    "    # Apply the function to create the 'Session' column\n",
    "    # function is in the define functions area\n",
    "    scheduling_conflicts_df['Session'] = scheduling_conflicts_df['Title'].apply(extract_session_number)\n",
    "\n",
    "    # Assign Role column based on where the contactID lives (fund or allocator)\n",
    "    scheduling_conflicts_df.loc[scheduling_conflicts_df['ContactId'].isin(fund_data_db['ContactID'].unique()), 'Role'] = 'Fund'\n",
    "    scheduling_conflicts_df.loc[scheduling_conflicts_df['ContactId'].isin(allocator_data_db['ContactID'].unique()), 'Role'] = 'Allocator'\n",
    "\n",
    "    scheduling_conflicts_df['FirstName'] = np.nan\n",
    "    scheduling_conflicts_df['LastName'] = np.nan\n",
    "\n",
    "    for contact_id in scheduling_conflicts_df['ContactId'].unique():\n",
    "\n",
    "        # if a fund\n",
    "        if scheduling_conflicts_df[scheduling_conflicts_df['ContactId'] == contact_id]['Role'].unique()[0] == 'Fund':\n",
    "\n",
    "            # Pull First name from fund df\n",
    "            firstname = fund_data_db[fund_data_db['ContactID'] == contact_id]['FirstName'].values[0]\n",
    "            scheduling_conflicts_df.loc[scheduling_conflicts_df['ContactId'] == contact_id, 'FirstName'] = firstname\n",
    "            # Pull Last name from fund data\n",
    "            lastname = fund_data_db[fund_data_db['ContactID'] == contact_id]['LastName'].values[0]\n",
    "            scheduling_conflicts_df.loc[scheduling_conflicts_df['ContactId'] == contact_id, 'LastName'] = lastname\n",
    "\n",
    "        # if a allocator\n",
    "        elif scheduling_conflicts_df[scheduling_conflicts_df['ContactId'] == contact_id]['Role'].unique()[0] == 'Allocator':# Pull First name from allocator data\n",
    "            scheduling_conflicts_df.loc[scheduling_conflicts_df['ContactId'] == contact_id, 'FirstName'] = allocator_data_db[allocator_data_db['ContactID'] == contact_id]['FirstName'].values[0]\n",
    "            # Pull Last name from fund data\n",
    "            scheduling_conflicts_df.loc[scheduling_conflicts_df['ContactId'] == contact_id, 'LastName'] = allocator_data_db[allocator_data_db['ContactID'] == contact_id]['LastName'].values[0]\n",
    "\n",
    "    # # Rearrange the columns \n",
    "    scheduling_conflicts_df = scheduling_conflicts_df[['FirstName', 'LastName', 'Role', 'Session','Title', 'ContactId']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dictionaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "metadata": {},
   "outputs": [],
   "source": [
    "allocators = allocator_data_db['Contact'].unique()\n",
    "funds = fund_data_db['Contact'].unique()\n",
    "attendees = list(set(funds).union(set(allocators)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Preferences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove cancelled people from prefs\n",
    "for contact in cancelled_contacts:\n",
    "    fund_data_db['Preference'] = fund_data_db['Preference'].str.replace(contact, '')\n",
    "    allocator_data_db['Preference'] = allocator_data_db['Preference'].str.replace(contact, '')\n",
    "    allocator_data_db['NoPreference'] = allocator_data_db['NoPreference'].str.replace(contact, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with 'Contact' as keys and 'Preference' as values\n",
    "fund_prefs_dict = {}\n",
    "\n",
    "for contact, preference in zip(fund_data_db['Contact'], fund_data_db['Preference']):\n",
    "    if preference is not None:\n",
    "        fund_prefs_dict[contact] = preference.split(',')\n",
    "    if preference is None:\n",
    "        fund_prefs_dict[contact] = None\n",
    "\n",
    "if set(list(fund_prefs_dict.keys())) != set(funds):\n",
    "    raise ValueError('Discrepency with funds in pref dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund_prefs_dict = {key: [value for value in values if value != ''] if values is not None else None for key, values in fund_prefs_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with 'Contact' as keys and 'Preference' as values\n",
    "allocator_prefs_dict = {}\n",
    "\n",
    "for contact, preference in zip(allocator_data_db['Contact'], allocator_data_db['Preference']):\n",
    "    if preference is not None:\n",
    "        allocator_prefs_dict[contact] = preference.split(',')\n",
    "    if preference is None:\n",
    "        allocator_prefs_dict[contact] = None\n",
    "\n",
    "if set(list(allocator_prefs_dict.keys())) != set(allocators):\n",
    "    raise ValueError('Discrepency with allocators in pref dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "metadata": {},
   "outputs": [],
   "source": [
    "allocator_prefs_dict = {key: [value for value in values if value != '' and value != 'cfa_F'] if values is not None else None for key, values in allocator_prefs_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create lists of preference pairs\n",
    "##### - Then sort the tuples to ensure consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund_pref_pairs = [(key, value) for key, values in fund_prefs_dict.items() if values is not None for value in values]\n",
    "# Sort tuples into ((F,A))\n",
    "temp_list = []\n",
    "for pair in fund_pref_pairs:\n",
    "    fund = [person for person in pair if person.endswith('_F')][0]\n",
    "    allocator = [person for person in pair if person.endswith('_A')][0]\n",
    "    temp_list.append((fund,allocator))\n",
    "fund_pref_pairs = temp_list\n",
    "# Remove tuples where the preferred allocator is not in this event \n",
    "fund_pref_pairs = [pair for pair in fund_pref_pairs if any(item in allocators for item in pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "metadata": {},
   "outputs": [],
   "source": [
    "allocator_pref_pairs = [(key, value) for key, values in allocator_prefs_dict.items() if values is not None for value in values]\n",
    "# Sort tuples into ((F,A))\n",
    "temp_list = []\n",
    "for pair in allocator_pref_pairs:\n",
    "    fund = [person for person in pair if person.endswith('_F')][0]\n",
    "    allocator = [person for person in pair if person.endswith('_A')][0]\n",
    "    temp_list.append((fund,allocator))\n",
    "allocator_pref_pairs = temp_list\n",
    "# Remove tuples where the preferred fund is not in this event \n",
    "allocator_pref_pairs = [pair for pair in allocator_pref_pairs if any(item in funds for item in pair)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### List of mutual preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_pref_pairs = set(allocator_pref_pairs).intersection(set(fund_pref_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Conflicts**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scheduling_conflicts_on:\n",
    "    # Separate them based on F or A \n",
    "    scheduling_conflicts_A = scheduling_conflicts_df.loc[scheduling_conflicts_df['Role'] == 'Allocator']\n",
    "    scheduling_conflicts_F = scheduling_conflicts_df.loc[scheduling_conflicts_df['Role'].isin(['Manager', 'Fund'])]\n",
    "\n",
    "    scheduling_conflicts_A['Contact'] = scheduling_conflicts_A['FirstName'].str.lower().str.strip() + '_' + scheduling_conflicts_A['LastName'].str.lower().str.strip() + '_A'\n",
    "    scheduling_conflicts_F['Contact'] = scheduling_conflicts_F['FirstName'].str.lower().str.strip() + '_' + scheduling_conflicts_F['LastName'].str.lower().str.strip() + '_F'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### These dictionaries are a list of people that ARE Available in each session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scheduling_conflicts_on:\n",
    "    # Allocator\n",
    "    allocator_scheduling_conflicts = {}\n",
    "    for i in range(1, number_sessions+1):\n",
    "        session_name = f\"Session {i}\"\n",
    "        allocator_scheduling_conflicts [f\"meeting_{i}_conflicts\"] = list(set((scheduling_conflicts_A.loc[scheduling_conflicts_A['Session'] == session_name])['Contact'].to_list()))\n",
    "\n",
    "    # if the contactID is NOT in scheduling_conflicts_A, add the name to every session \n",
    "    allocators_without_availability  = allocator_data_db[allocator_data_db['ContactID'].isin(list(set(allocator_data_db['ContactID'].unique())- set(scheduling_conflicts_A['ContactId'].unique())))]['Contact'].tolist()\n",
    "    allocators_without_availability.remove('ian_smith_A')\n",
    "    for i in range(1, number_sessions+1):\n",
    "        allocator_scheduling_conflicts [f\"meeting_{i}_conflicts\"] = allocator_scheduling_conflicts [f\"meeting_{i}_conflicts\"] + allocators_without_availability\n",
    "\n",
    "\n",
    "    # Funds \n",
    "    fund_scheduling_conflicts = {}\n",
    "    for i in range(1, number_sessions+1):\n",
    "        session_name = f\"Session {i}\"\n",
    "        fund_scheduling_conflicts [f\"meeting_{i}_conflicts\"] = list(set((scheduling_conflicts_F.loc[scheduling_conflicts_F['Session'] == session_name])['Contact'].to_list()))\n",
    "\n",
    "    # if the contactID is NOT in scheduling_conflicts_F, add the name to every session \n",
    "    funds_without_availability  = fund_data_db[fund_data_db['ContactID'].isin(list(set(fund_data_db['ContactID'].unique())- set(scheduling_conflicts_F['ContactId'].unique())))]['Contact'].tolist()\n",
    "    for i in range(1, number_sessions+1):\n",
    "        fund_scheduling_conflicts [f\"meeting_{i}_conflicts\"] = fund_scheduling_conflicts [f\"meeting_{i}_conflicts\"] + funds_without_availability\n",
    "\n",
    "\n",
    "else: \n",
    "    allocator_scheduling_conflicts = {}\n",
    "    for i in range(1, number_sessions+1):\n",
    "        allocator_scheduling_conflicts [f\"meeting_{i}_conflicts\"] = set(allocators)\n",
    "\n",
    "    fund_scheduling_conflicts = {}\n",
    "    for i in range(1, number_sessions+1):\n",
    "        fund_scheduling_conflicts [f\"meeting_{i}_conflicts\"] = set(funds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, number_sessions+1):\n",
    "    print('ian_smith_A' in allocator_scheduling_conflicts[f'meeting_{i}_conflicts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n",
      "84\n",
      "84\n",
      "83\n",
      "83\n",
      "84\n",
      "77\n",
      "85\n"
     ]
    }
   ],
   "source": [
    "# Check for people missing from different sessions\n",
    "for i in range(1, number_sessions+1):\n",
    "    print(len(allocator_scheduling_conflicts[f\"meeting_{i}_conflicts\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "39\n",
      "40\n",
      "40\n",
      "40\n",
      "39\n",
      "39\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "# Check for people missing from different sessions\n",
    "for i in range(1, number_sessions+1):\n",
    "    print(len(fund_scheduling_conflicts[f\"meeting_{i}_conflicts\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Dictionary of which sessions people ARE available**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scheduling_conflicts_on:\n",
    "\n",
    "    # Allocators \n",
    "    allocator_available_sessions ={}\n",
    "    for contact in scheduling_conflicts_A['Contact'].unique().tolist():\n",
    "        allocator_available_sessions[contact] = [int(re.search(r'\\d+', session).group()) for session in scheduling_conflicts_A[scheduling_conflicts_A['Contact'] == contact]['Session']]\n",
    "\n",
    "    # For allocators that did not fill out availability - assume available for all \n",
    "    for contact in allocators_without_availability:\n",
    "        allocator_available_sessions[contact] = [i for i in range(1, number_sessions+1)]\n",
    "\n",
    "\n",
    "    # Funds \n",
    "    fund_available_sessions ={}\n",
    "    for contact in scheduling_conflicts_F['Contact'].unique().tolist():\n",
    "        fund_available_sessions[contact] = [int(re.search(r'\\d+', session).group()) for session in scheduling_conflicts_F[scheduling_conflicts_F['Contact'] == contact]['Session']]\n",
    "\n",
    "    # For funds that did not fill out availability - assume available for all \n",
    "    for contact in funds_without_availability:\n",
    "        fund_available_sessions[contact] = [i for i in range(1, number_sessions+1)]\n",
    "\n",
    "else:\n",
    "    # Create a dictionary called allocator_available_sessions\n",
    "    allocator_available_sessions = {allocator: list(range(1, number_sessions+1)) for allocator in allocators}\n",
    "    fund_available_sessions = {fund: list(range(1, number_sessions+1)) for fund in funds}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Allocator No Prefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with 'Contact' as keys and 'Preference' as values\n",
    "allocator_no_prefs_dict = {}\n",
    "\n",
    "for contact, preference in zip(allocator_data_db['Contact'], allocator_data_db['NoPreference']):\n",
    "    if preference is not None:\n",
    "        allocator_no_prefs_dict[contact] = preference.split(',')\n",
    "    if preference is None:\n",
    "        allocator_no_prefs_dict[contact] = None\n",
    "\n",
    "if set(list(allocator_no_prefs_dict.keys())) != set(allocators):\n",
    "    raise ValueError('Discrepency with allocators in pref dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "metadata": {},
   "outputs": [],
   "source": [
    "allocator_no_pref_pairs = [(key, value) for key, values in allocator_no_prefs_dict.items() if values is not None for value in values]\n",
    "# Sort tuples \n",
    "temp_list = []\n",
    "for pair in allocator_no_pref_pairs:\n",
    "    fund = [person for person in pair if person.endswith('_F')][0]\n",
    "    allocator = [person for person in pair if person.endswith('_A')][0]\n",
    "    temp_list.append((fund,allocator))\n",
    "allocator_no_pref_pairs = temp_list\n",
    "# Remove tuples where the preferred fund is not in this event \n",
    "allocator_no_pref_pairs = [pair for pair in allocator_no_pref_pairs if any(item in funds for item in pair)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Pair Counts**\n",
    "- generate a list of pairs and then sort the tuples for consistent\n",
    "- Blow out to sessions or tables, look at combinations of tables in sessions and then go from there \n",
    "- How many combinations of F/A table structures are there - look at all of these in combination form and then aim to differ the following tables from this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate combinations\n",
    "pair_count_list = list(combinations(attendees, 2))\n",
    "pair_count_list = list(set(pair_count_list)) # remove duplicates\n",
    "\n",
    "\n",
    "# Sort each tuple within the list\n",
    "temp_list = []\n",
    "for pair in pair_count_list:\n",
    "    # If its two funds or two allocators, no need to do anything just add them back in \n",
    "    if (pair[0] in funds and pair[1] in funds) or (pair[0] in allocators and pair[1] in allocators):\n",
    "        temp_list.append((pair[0],pair[1]))\n",
    "    # If its a fund/allocator pairschedu\n",
    "    else:\n",
    "        fund = [person for person in pair if person.endswith('_F')][0]\n",
    "        allocator = [person for person in pair if person.endswith('_A')][0]\n",
    "        temp_list.append((fund,allocator))\n",
    "\n",
    "pair_count_list = temp_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Fund Allocator Pairs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "metadata": {},
   "outputs": [],
   "source": [
    "FA_pairs = []\n",
    "for fund in funds:\n",
    "    for allocator in allocators:\n",
    "        FA_pairs.append((fund,allocator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **AUM and Primary Strat pairs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "metadata": {},
   "outputs": [],
   "source": [
    "aum_matches =  []\n",
    "aum_no_matches =  []\n",
    "\n",
    "for pair in FA_pairs:\n",
    "\n",
    "    fund_contact = [value for value in pair if value.endswith('_F')][0]\n",
    "    fund_aum = fund_data_db[fund_data_db['Contact'] == fund_contact]['AUM Range'].values[0]\n",
    "\n",
    "    allocator_contact = [value for value in pair if value.endswith('_A')][0]\n",
    "    allocator_aum_pref_1 = allocator_data_db[allocator_data_db['Contact'] == allocator_contact]['Manager Size Preference 1'].values[0]\n",
    "    allocator_aum_pref_2 = allocator_data_db[allocator_data_db['Contact'] == allocator_contact]['Manager Size Preference 2'].values[0]\n",
    "\n",
    "\n",
    "    # AUM MATCHES \n",
    "\n",
    "    # If fund AUM matches Allocator first pick AUM \n",
    "    if fund_aum == allocator_aum_pref_1: \n",
    "        aum_matches.append([fund_contact, allocator_contact, fund_aum, allocator_aum_pref_1])\n",
    "        # print(fund_aum, allocator_aum_pref_1)\n",
    "\n",
    "    # If fund AUM matches Allocator second pick AUM \n",
    "    elif fund_aum == allocator_aum_pref_2:\n",
    "        aum_matches.append([fund_contact, allocator_contact, fund_aum, allocator_aum_pref_2])\n",
    "        # print(fund_aum, allocator_aum_pref_2)\n",
    "\n",
    "    # else: \n",
    "    #     print(fund_aum,'-', allocator_aum_pref_1,'-', allocator_aum_pref_2)\n",
    "    # AUM NO MATCHES \n",
    "    elif fund_aum  == '$0.5B - $2B' and (allocator_aum_pref_1 in [ '$5B - $10B','Over $10B']  or allocator_aum_pref_2 in [ '$5B - $10B','Over $10B']) :\n",
    "        aum_no_matches.append([fund_contact, allocator_contact, fund_aum, allocator_aum_pref_1, allocator_aum_pref_2])\n",
    "        # print(fund_aum,'-', allocator_aum_pref_1,'-', allocator_aum_pref_2)\n",
    "\n",
    "    elif fund_aum  =='Over $10B' and (allocator_aum_pref_1 in ['$0.5B - $2B', '$2B - $5B']  or allocator_aum_pref_2 in ['$0.5B - $2B', '$2B - $5B']):\n",
    "        aum_no_matches.append([fund_contact, allocator_contact, fund_aum, allocator_aum_pref_1, allocator_aum_pref_2])\n",
    "        # print(fund_aum,'-', allocator_aum_pref_1,'-', allocator_aum_pref_2)\n",
    "\n",
    "# The remaining (below) not matching or not matching, they are in ~limbo~ where they do not need to be minimized or maximized\n",
    "        \n",
    "    # else:\n",
    "    #     if fund_aum is not None: #and not np.isnan(allocator_aum_pref_1) and not np.isnan(allocator_aum_pref_2):\n",
    "            # print(fund_aum,'-', allocator_aum_pref_1,'-', allocator_aum_pref_2)\n",
    "\n",
    "# print('if nothing prints, then all pairs where fund and allocator both have a value are either in matches or no matches')\n",
    "\n",
    "aum_matches_pairs = [(item[0], item[1]) for item in aum_matches]\n",
    "\n",
    "aum_no_matches_pairs = [(item[0], item[1]) for item in aum_no_matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the one not sorted by pair count list\n",
    "\n",
    "fund_aum_matches_og= []\n",
    "\n",
    "for fund1 in funds:\n",
    "    fund1_aum_class = fund_data_db[fund_data_db['Contact']==fund1]['AUM Range'].values[0]\n",
    "\n",
    "    for fund2 in funds:\n",
    "        fund2_aum_class = fund_data_db[fund_data_db['Contact']==fund2]['AUM Range'].values[0]\n",
    "        if fund1_aum_class == fund2_aum_class and fund1_aum_class != None:\n",
    "            # print(fund1,fund1_aum_class, fund2, fund2_aum_class )\n",
    "            fund_aum_matches_og.append((fund1, fund2))\n",
    "\n",
    "# Sort them by pair count list \n",
    "fund_aum_matches = []\n",
    "for pair in fund_aum_matches_og:\n",
    "    if pair in pair_count_list:\n",
    "        fund_aum_matches.append(pair)\n",
    "        # print('ok')\n",
    "    elif (pair[1], pair[0]) in pair_count_list:\n",
    "        fund_aum_matches.append((pair[1], pair[0]))\n",
    "        # print('flipping!')\n",
    "    elif pair[1] != pair[0]:\n",
    "        raise ValueError('uh oh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund_aum_NO_matches_og= []\n",
    "\n",
    "for fund1 in funds:\n",
    "    fund1_aum_class = fund_data_db[fund_data_db['Contact']==fund1]['AUM Range'].values[0]\n",
    "\n",
    "    for fund2 in funds:\n",
    "        fund2_aum_class = fund_data_db[fund_data_db['Contact']==fund2]['AUM Range'].values[0]\n",
    "\n",
    "        if (fund1_aum_class == 'Under $0.5B' and fund2_aum_class in  ['$2B - $5B', '$5B - $10B', 'Over $10B']) or (fund2_aum_class == 'Under $0.5B' and fund1_aum_class in  [ '$2B - $5B', '$5B - $10B', 'Over $10B']):\n",
    "            fund_aum_NO_matches_og.append((fund1, fund2))\n",
    "\n",
    "        elif (fund1_aum_class == '$0.5B - $2B' and fund2_aum_class in  [ '$5B - $10B', 'Over $10B']) or (fund2_aum_class == '$0.5B - $2B' and fund1_aum_class in  ['$5B - $10B', 'Over $10B']):\n",
    "            fund_aum_NO_matches_og.append((fund1, fund2))\n",
    "\n",
    "        elif (fund1_aum_class == '$5B - $10B' and fund2_aum_class in  ['Under $0.5B', '$0.5B - $2B']) or (fund2_aum_class == '$5B - $10B' and fund1_aum_class in  ['Under $0.5B', '$0.5B - $2B']):\n",
    "            fund_aum_NO_matches_og.append((fund1, fund2))\n",
    "\n",
    "        elif( fund1_aum_class == 'Over $10B' and fund2_aum_class in  ['Under $0.5B', '$0.5B - $2B', '$2B - $5B']) or ( fund2_aum_class == 'Over $10B' and fund1_aum_class in  ['Under $0.5B', '$0.5B - $2B', '$2B - $5B']):\n",
    "            fund_aum_NO_matches_og.append((fund1, fund2))\n",
    "\n",
    "        elif (fund1_aum_class == '$2B - $5B' and fund2_aum_class in  ['Under $0.5B', 'Over $10B']) or (fund2_aum_class == '$2B - $5B' and fund1_aum_class in  ['Under $0.5B', 'Over $10B']):\n",
    "            fund_aum_NO_matches_og.append((fund1, fund2))\n",
    "\n",
    "# Sort them by pair count lust \n",
    "fund_aum_NO_matches = []\n",
    "for pair in fund_aum_NO_matches_og:\n",
    "    if pair in pair_count_list:\n",
    "        fund_aum_NO_matches.append(pair)\n",
    "        # print('ok')\n",
    "    elif (pair[1], pair[0]) in pair_count_list:\n",
    "        fund_aum_NO_matches.append((pair[1], pair[0]))\n",
    "        # print('flipping!')\n",
    "    elif pair[1] != pair[0]:\n",
    "        raise ValueError('uh oh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Asset Class Matches**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fund to fund asset class matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1008,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund_assetclass_matches_og= []\n",
    "\n",
    "for fund1 in funds:\n",
    "        fund1_asset_class = fund_data_db[fund_data_db ['Contact']==fund1]['Firm Asset Class'].unique()\n",
    "        for fund2 in funds:\n",
    "            fund2_asset_class = fund_data_db[fund_data_db ['Contact']==fund2]['Firm Asset Class'].unique()\n",
    "            if  fund1_asset_class != None and fund2_asset_class != None and fund1_asset_class == fund2_asset_class: \n",
    "                fund_assetclass_matches_og.append((fund1, fund2))\n",
    "\n",
    "# Sort them by pair count lust \n",
    "fund_assetclass_matches = []\n",
    "for pair in fund_assetclass_matches_og:\n",
    "    if pair in pair_count_list:\n",
    "        fund_assetclass_matches.append(pair)\n",
    "        # print('ok')\n",
    "    elif (pair[1], pair[0]) in pair_count_list:\n",
    "        fund_assetclass_matches.append((pair[1], pair[0]))\n",
    "        # print('flipping!')\n",
    "    elif pair[1] != pair[0]:\n",
    "        print('uh oh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Allocator Institution Matches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the value is an empty string make it null!\n",
    "# allocator_data_db.loc[allocator_data_db['Description Of Organization'] == '', 'Description Of Organization'] = None\n",
    "allocator_data_db.loc[allocator_data_db['*Description of Organization'] == '', '*Description of Organization'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "metadata": {},
   "outputs": [],
   "source": [
    "institution_matches_og =[]\n",
    "\n",
    "for allocator1 in allocators:\n",
    "    allocator1_institution_type = allocator_data_db[allocator_data_db['Contact']==allocator1]['*Description of Organization'].values[0]\n",
    "    for allocator2 in allocators:\n",
    "        allocator2_institution_type = allocator_data_db[allocator_data_db['Contact']==allocator2]['*Description of Organization'].values[0]\n",
    "        \n",
    "        if allocator1_institution_type == allocator2_institution_type:\n",
    "            # print(allocator1_institution_type, allocator2_institution_type)\n",
    "            institution_matches_og.append((allocator1, allocator2))\n",
    "\n",
    "# remove duplicates\n",
    "institution_matches_og = list(set(institution_matches_og))\n",
    "\n",
    "# Sort them by pair count lust \n",
    "institution_matches = []\n",
    "for pair in institution_matches_og:\n",
    "    if pair in pair_count_list:\n",
    "        institution_matches.append(pair)\n",
    "        # print('ok')\n",
    "    elif (pair[1], pair[0]) in pair_count_list:\n",
    "        institution_matches.append((pair[1], pair[0]))\n",
    "    elif pair[1] != pair[0]:\n",
    "        print('uh oh')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skeleton of Seating Arrangement "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format & Output Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_tables_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_frameworks = {}\n",
    "for session in range(1, number_sessions+1):\n",
    "    if session != 8:\n",
    "        table_frameworks[f'Session {session}'] = {}\n",
    "        for table in range(1, number_tables_dict[session]+1):\n",
    "            # print(table)\n",
    "            table_frameworks[f'Session {session}'][f'Table {table}'] = ()\n",
    "            assignments = adjusted_frameworks_df[(adjusted_frameworks_df['Table'] == f'Table {table}') & (adjusted_frameworks_df['Session'].str.contains(f'{session}'))]['Company Type'].dropna().tolist()\n",
    "            assignments = [value for value in assignments if value != 'Facilitator']\n",
    "            assignments = sorted(['F' if value == 'Manager' else 'A' for value in assignments])\n",
    "            table_frameworks[f'Session {session}'][f'Table {table}'] = tuple(assignments)\n",
    "\n",
    "table_frameworks[f'Session 8'] = {}\n",
    "for table in range(1, number_tables_dict[8]+1):\n",
    "    assignments = adjusted_frameworks_df[(adjusted_frameworks_df['Table'] == f'Table {table}') & (adjusted_frameworks_df['Session'].str.contains(f'Lunch'))]['Company Type'].dropna().tolist()\n",
    "    assignments = [value for value in assignments if value != 'Facilitator']\n",
    "    assignments = sorted(['F' if value == 'Manager' else 'A' for value in assignments])\n",
    "    table_frameworks[f'Session {8}'][f'Table {table}'] = tuple(assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session 1 : All tables are seated? True\n",
      "Session 2 : All tables are seated? True\n",
      "Session 3 : All tables are seated? True\n",
      "Session 4 : All tables are seated? True\n",
      "Session 5 : All tables are seated? True\n",
      "Session 6 : All tables are seated? True\n",
      "Session 7 : All tables are seated? True\n",
      "Session 8 : All tables are seated? True\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, number_sessions + 1):\n",
    "    session_tables = table_frameworks[f'Session {i}']\n",
    "    print(f'Session {i} : All tables are seated?',\n",
    "        len(list(session_tables.values())) == number_tables_dict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_size_dict = {}\n",
    "\n",
    "for i in range(1, number_sessions+1):\n",
    "    # create a subdictionary for this session \n",
    "    table_size_dict[i] = {}\n",
    "    framework = table_frameworks[f'Session {i}'] \n",
    "    for table in framework:\n",
    "        # table_size_dict[i][table] = {}\n",
    "        assignments = framework[table]\n",
    "        table_size_dict[i][table] = len(assignments)\n",
    "        # table_size_dict[i][table]['A'] = assignments.count('A')\n",
    "        # table_size_dict[i][table]['F'] = assignments.count('F')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quality Check - Check that all tables are utilized in each session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session 1 : All tables are seated? True\n",
      "Session 2 : All tables are seated? True\n",
      "Session 3 : All tables are seated? True\n",
      "Session 4 : All tables are seated? True\n",
      "Session 5 : All tables are seated? True\n",
      "Session 6 : All tables are seated? True\n",
      "Session 7 : All tables are seated? True\n",
      "Session 8 : All tables are seated? True\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, number_sessions + 1):\n",
    "    session_tables = table_frameworks[f'Session {i}']\n",
    "    print(f'Session {i} : All tables are seated?',\n",
    "        len(list(session_tables.values())) == number_tables_dict[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format & Output Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create dataframe from dictionary\n",
    "table_frameworks_df = pd.DataFrame(table_frameworks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Ratio Value Counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Session 1</th>\n",
       "      <th>Session 2</th>\n",
       "      <th>Session 3</th>\n",
       "      <th>Session 4</th>\n",
       "      <th>Session 5</th>\n",
       "      <th>Session 6</th>\n",
       "      <th>Session 7</th>\n",
       "      <th>Session 8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0/6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0/7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4/2</th>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/2</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6/0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6/3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7/0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8/0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Session 1  Session 2  Session 3  Session 4  Session 5  Session 6  \\\n",
       "0/6          0          0          0          2          0          0   \n",
       "0/7          0          0          0          4          0          0   \n",
       "3/2          0          0          0          0          0          0   \n",
       "4/2         15         12         16          0         17         12   \n",
       "5/2          5          6          4          0          3          6   \n",
       "5/3          0          0          0          0          0          1   \n",
       "6/0          0          0          0          3          0          0   \n",
       "6/3          0          1          0          0          0          0   \n",
       "7/0          0          0          0          7          0          0   \n",
       "8/0          0          0          0          2          0          0   \n",
       "\n",
       "     Session 7  Session 8  \n",
       "0/6          0          0  \n",
       "0/7          0          0  \n",
       "3/2          2          0  \n",
       "4/2         15          0  \n",
       "5/2          1          8  \n",
       "5/3          1          3  \n",
       "6/0          0          0  \n",
       "6/3          0          5  \n",
       "7/0          0          0  \n",
       "8/0          0          0  "
      ]
     },
     "execution_count": 1018,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary to store the counts for each ratio\n",
    "ratio_counts = {}\n",
    "\n",
    "# Iterate over sessions and tables\n",
    "\n",
    "for session, tables in table_frameworks.items():\n",
    "    for table, contents in tables.items():\n",
    "        # Calculate the ratio of A to F for each table\n",
    "        ratio = f\"{contents.count('A')}/{contents.count('F')}\"\n",
    "        \n",
    "        # Increment the count in the dictionary\n",
    "        ratio_counts.setdefault(ratio, {}).setdefault(session, 0)\n",
    "        ratio_counts[ratio][session] += 1\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "df_counts = pd.DataFrame(ratio_counts)\n",
    "\n",
    "# Transpose the DataFrame for the desired format\n",
    "ratio_counts_df = df_counts.T.fillna(0).astype(int).sort_index()\n",
    "\n",
    "# Rearrange to be chronological\n",
    "ratio_counts_df = ratio_counts_df[[f'Session {i}' for i in range(1, number_sessions+1)]]\n",
    "\n",
    "# print\n",
    "ratio_counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the number of Tables for each Session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_tables_df = pd.DataFrame(number_tables_dict.items(), columns=['Session', 'Number of Tables']).set_index('Session').T\n",
    "number_tables_df.columns = ratio_counts_df.columns\n",
    "\n",
    "# Add table counts to ratio \n",
    "ratio_counts_df = pd.concat([number_tables_df, ratio_counts_df])\n",
    "\n",
    "# Set secondary column index as Number of Tables \n",
    "ratio_counts_df = ratio_counts_df.T.reset_index().rename(columns = {'index':'Session'}).set_index(['Session', 'Number of Tables']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataFrame for Total counts per Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store the counts\n",
    "counts_dict = {}\n",
    "\n",
    "# Iterate through sessions and tables\n",
    "for session, tables in table_frameworks.items():\n",
    "    session_counts = {'Funds': 0, 'Allocators': 0}\n",
    "    \n",
    "    for table, contents in tables.items():\n",
    "        # Count the occurrences of 'A' and 'F' in each table\n",
    "        session_counts['Funds'] += contents.count('F')\n",
    "        session_counts['Allocators'] += contents.count('A')\n",
    "\n",
    "    # Store the counts in the dictionary\n",
    "    counts_dict[(session, 'Funds')] = session_counts['Funds']\n",
    "    counts_dict[(session, 'Allocators')] = session_counts['Allocators']\n",
    "    \n",
    "data = counts_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Session 1</th>\n",
       "      <th>Session 2</th>\n",
       "      <th>Session 3</th>\n",
       "      <th>Session 4</th>\n",
       "      <th>Session 5</th>\n",
       "      <th>Session 6</th>\n",
       "      <th>Session 7</th>\n",
       "      <th>Session 8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Role</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Allocators</th>\n",
       "      <td>85</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>76</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Funds</th>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Session 1  Session 2  Session 3  Session 4  Session 5  Session 6  \\\n",
       "Role                                                                           \n",
       "Allocators         85         84         84         83         83         83   \n",
       "Funds              40         39         40         40         40         39   \n",
       "\n",
       "            Session 7  Session 8  \n",
       "Role                              \n",
       "Allocators         76         85  \n",
       "Funds              39         40  "
      ]
     },
     "execution_count": 1021,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a dictionary to store the counts\n",
    "data = {}\n",
    "\n",
    "# Iterate through sessions and tables\n",
    "for session, tables in table_frameworks.items():\n",
    "    session_counts = {'Funds': 0, 'Allocators': 0}\n",
    "    \n",
    "    for table, contents in tables.items():\n",
    "        # Count the occurrences of 'A' and 'F' in each table\n",
    "        session_counts['Funds'] += contents.count('F')\n",
    "        session_counts['Allocators'] += contents.count('A')\n",
    "\n",
    "    # Store the counts in the dictionary\n",
    "    data[(session, 'Funds')] = session_counts['Funds']\n",
    "    data[(session, 'Allocators')] = session_counts['Allocators']\n",
    "\n",
    "\n",
    "# Create a dataframe from the dictionary\n",
    "FA_counts_df = pd.DataFrame.from_dict(data, orient='index', columns=['Value'])\n",
    "\n",
    "# Rename the row and column indices\n",
    "FA_counts_df.index.names = ['Session']\n",
    "\n",
    "# Print the dataframe\n",
    "FA_counts_df = FA_counts_df.reset_index()\n",
    "\n",
    "FA_counts_df['Session'] = FA_counts_df['Session'].apply(str)\n",
    "FA_counts_df[['Session', 'Role']] = FA_counts_df['Session'].str.split(',', expand=True)\n",
    "FA_counts_df['Session'] = FA_counts_df['Session'].str[2:-1].str.strip()\n",
    "FA_counts_df['Role'] = FA_counts_df['Role'].str[2:-2].str.strip()\n",
    "FA_counts_df = FA_counts_df.rename(columns = {'Value':'Count'})\n",
    "\n",
    "# Set index as Session and Role\n",
    "FA_counts_df = FA_counts_df.set_index(['Session', 'Role'])\n",
    "\n",
    "# pivot the table so that Sessions are across the top and Funds/Allocators are rows\n",
    "FA_counts_df = FA_counts_df.reset_index().pivot(index='Role', columns='Session', values='Count')\n",
    "\n",
    "# filter to only rows that have 'Fund' or 'Allocator'\n",
    "FA_counts_df = FA_counts_df[FA_counts_df.index.isin(['Funds', 'Allocators'])]\n",
    "\n",
    "# remove the name of the columns index\n",
    "FA_counts_df.columns.name = None\n",
    "\n",
    "# Preview df\n",
    "FA_counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring in the Seating Assignments that Hank Sent over "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_frameworks_df['Contact'] = adjusted_frameworks_df['Name'].str.lower().str.strip().str.replace(\"  \", ' ').str.replace(' ', '_')\n",
    "\n",
    "adjusted_frameworks_df.loc[adjusted_frameworks_df['Company Type'] == 'Manager', 'Contact'] = adjusted_frameworks_df['Contact'] + '_F'\n",
    "adjusted_frameworks_df.loc[adjusted_frameworks_df['Company Type'] == 'Allocator', 'Contact'] = adjusted_frameworks_df['Contact'] + '_A'\n",
    "adjusted_frameworks_df.loc[adjusted_frameworks_df['Company Type'] == 'Facilitator', 'Contact'] = adjusted_frameworks_df['Contact'] + '_S'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "metadata": {},
   "outputs": [],
   "source": [
    "meeting_assignments  = {}\n",
    "for session in range(1, number_sessions+1):\n",
    "    if session != 8:\n",
    "        meeting_assignments[f'Session {session}'] = {}\n",
    "        for table in range(1, number_tables_dict[session]+1):\n",
    "            # print(table)\n",
    "            # meeting_assignments[f'Session {session}'][table]= []\n",
    "            assignments = adjusted_frameworks_df[(adjusted_frameworks_df['Table'] == f'Table {table}') & (adjusted_frameworks_df['Session'].str.contains(f'{session}'))]['Contact'].dropna().tolist()\n",
    "            meeting_assignments[f'Session {session}'][table]= assignments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (2173944595.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1024], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    for seat in range(1, 10)\u001b[0m\n\u001b[1;37m                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "meeting_assignments[f'Session 8'] = {}\n",
    "for table in range(1, number_tables_dict[8]+1):\n",
    "    for seat in range(1, 11): \n",
    "\n",
    "        assignments = adjusted_frameworks_df[(adjusted_frameworks_df['Table'] == f'Table {table}') & (adjusted_frameworks_df['Session'].str.contains(f'Lunch'))]['Contact'].dropna().tolist()\n",
    "        meeting_assignments[f'Session 8'][table]= assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1032,
   "metadata": {},
   "outputs": [],
   "source": [
    "seat = 5\n",
    "\n",
    "table = 6\n",
    "session = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "metadata": {},
   "outputs": [],
   "source": [
    "meeting_assignments['Session 8'] = {}\n",
    "\n",
    "for table in range(1, number_tables_dict[8]+1):\n",
    "    meeting_assignments['Session 8'][table] = {}\n",
    "    for seat in range(1, 11):\n",
    "        name = adjusted_frameworks_df[(adjusted_frameworks_df['Table'] == f'Table {table}') & (adjusted_frameworks_df['Session'].str.contains('Lunch'))& (adjusted_frameworks_df['Seat'] == f'{seat}')]['Contact'].values[0]\n",
    "        if pd.notna(name):\n",
    "            meeting_assignments['Session 8'][table][seat] = name\n",
    "        else:\n",
    "            meeting_assignments['Session 8'][table][seat] = ()\n",
    "\n",
    "# assignments = [value for value in assignments if not pd.isna(value)]\n",
    "# print(assignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "metadata": {},
   "outputs": [],
   "source": [
    "lunch_table_assignments = {}\n",
    "lunch_table_assignments['Session 8'] = meeting_assignments['Session 8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1068,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary to store pair counts # \n",
    "lunch_pair_counts = {}\n",
    "\n",
    "# Iterate through sessions and table assignments\n",
    "for session, table_assignments in lunch_table_assignments.items():\n",
    "    # Iterate through tables and assigned names\n",
    "    for table, assigned_names in table_assignments.items():\n",
    "        # print(assigned_names)\n",
    "        # Iterate through pairs of assigned names\n",
    "        for seat_pairs in [(i, i % 10 + 1) for i in range(1, 11)]:\n",
    "            if assigned_names[seat_pairs[0]] != () and assigned_names[seat_pairs[1]] != ():\n",
    "                lunch_pair_counts[(assigned_names[seat_pairs[0]], assigned_names[seat_pairs[1]])] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1069,
   "metadata": {},
   "outputs": [],
   "source": [
    "lunch_satisfied_allocator_pref_pairs = list(set([pair for pair in allocator_pref_pairs if pair in lunch_pair_counts or (pair[1], pair[0]) in lunch_pair_counts]))\n",
    "lunch_satisfied_fund_pref_pairs =list(set([pair for pair in fund_pref_pairs if pair in lunch_pair_counts or (pair[1], pair[0]) in lunch_pair_counts]))\n",
    "lunch_satisfied_mutual_pref_pairs = list(set([pair for pair in mutual_pref_pairs if pair in lunch_pair_counts  or (pair[1], pair[0]) in lunch_pair_counts]))\n",
    "lunch_satisfied_fund_assetclass_pairs = list(set([pair for pair in fund_assetclass_matches if pair in lunch_pair_counts  or (pair[1], pair[0]) in lunch_pair_counts]))\n",
    "lunch_satisfied_fund_aum_pairs = list(set([pair for pair in fund_aum_matches if pair in lunch_pair_counts  or (pair[1], pair[0]) in lunch_pair_counts]))\n",
    "lunch_satisfied_allocator_nopref_pairs = list(set([pair for pair in allocator_no_pref_pairs if pair in lunch_pair_counts  or (pair[1], pair[0]) in lunch_pair_counts]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remaining_mutual_pref_pairs = [pair for pair in mutual_pref_pairs if pair not in lunch_satisfied_mutual_pref_pairs ]\n",
    "# remaining_allocator_pref_pairs =[pair for pair in allocator_pref_pairs if pair not in lunch_satisfied_allocator_pref_pairs]\n",
    "# remaining_fund_pref_pairs = [pair for pair in fund_pref_pairs if pair not in lunch_satisfied_fund_pref_pairs ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LUNCH\n",
      "13.59 % Allocator prefs satsified  in Lunch\n",
      "4.9 % Fund prefs satsified in Lunch\n",
      "8.33 % Mutual prefs satsified in Lunch\n",
      "0.0 % No prefs satsified  in Lunch\n"
     ]
    }
   ],
   "source": [
    "print('LUNCH')\n",
    "if  len(allocator_pref_pairs) > 0:\n",
    "    print(round((len(set(lunch_satisfied_allocator_pref_pairs)) / len(allocator_pref_pairs) )*100, 2) , '% Allocator prefs satsified  in Lunch')\n",
    "if  len(fund_pref_pairs) > 0:\n",
    "    print(round((len(set(lunch_satisfied_fund_pref_pairs)) / len(fund_pref_pairs))*100, 2) , '% Fund prefs satsified in Lunch')\n",
    "if  len(mutual_pref_pairs) > 0:\n",
    "    print(round((len(set(lunch_satisfied_mutual_pref_pairs)) / len(mutual_pref_pairs))*100, 2) , '% Mutual prefs satsified in Lunch')\n",
    "if  len(allocator_no_pref_pairs) > 0:\n",
    "    print(round((len(set(lunch_satisfied_allocator_nopref_pairs)) / len(allocator_no_pref_pairs))*100, 2), '% No prefs satsified  in Lunch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary to store pair counts # \n",
    "lunch_table_pair_counts = {}\n",
    "for pair in pair_count_list:\n",
    "    for table in lunch_table_assignments['Session 8']:\n",
    "        assignments = lunch_table_assignments['Session 8'][table]\n",
    "        if pair[0] in assignments and pair[1] in assignments:\n",
    "            lunch_table_pair_counts[pair] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manager / Allocator only Session\n",
    "##### - match on institution type for A "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Added consideration: \n",
    "- For institution types that have multiple tables, try to match on AUM as well\n",
    "- E&F has two tables\n",
    "- OCIO has two tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1072,
   "metadata": {},
   "outputs": [],
   "source": [
    "EandF_allocators = allocator_data_db[allocator_data_db['*Description of Organization'] == 'E&F']['Contact'].to_list()\n",
    "Pension_allocators = allocator_data_db[allocator_data_db['*Description of Organization'] == 'Pension']['Contact'].to_list()\n",
    "OCIO_allocators = allocator_data_db[allocator_data_db['*Description of Organization'] == 'OCIO']['Contact'].to_list()\n",
    "SFO_allocators = allocator_data_db[allocator_data_db['*Description of Organization'] == 'SFO']['Contact'].to_list()\n",
    "MFO_allocators = allocator_data_db[allocator_data_db['*Description of Organization'] == 'MFO']['Contact'].to_list()\n",
    "Hospital_allocators = allocator_data_db[allocator_data_db['*Description of Organization'] == 'Hospital']['Contact'].to_list()\n",
    "Consultant_allocators = allocator_data_db[allocator_data_db['*Description of Organization'] == 'Consultant']['Contact'].to_list()\n",
    "\n",
    "\n",
    "# Allocators that match on these specifically\n",
    "EandF_Matching_pairs = [pair for pair in list(itertools.combinations(EandF_allocators, 2)) if pair in pair_count_list]\n",
    "Pension_Matching_pairs = [pair for pair in list(itertools.combinations(Pension_allocators, 2)) if pair in pair_count_list]\n",
    "OCIO_Matching_pairs = [pair for pair in list(itertools.combinations(OCIO_allocators, 2)) if pair in pair_count_list]\n",
    "SFO_Matching_pairs = [pair for pair in list(itertools.combinations(SFO_allocators, 2)) if pair in pair_count_list]\n",
    "MFO_Matching_pairs = [pair for pair in list(itertools.combinations(MFO_allocators, 2)) if pair in pair_count_list]\n",
    "Hospital_Matching_pairs = [pair for pair in list(itertools.combinations(Hospital_allocators, 2)) if pair in pair_count_list]\n",
    "Consultant_Matching_pairs = [pair for pair in list(itertools.combinations(Consultant_allocators, 2)) if pair in pair_count_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "metadata": {},
   "outputs": [],
   "source": [
    "allocator_data_db['AUM Range'] = allocator_data_db['AUM Range'].str.replace('>$10B',  '11').str.replace('$5B - $10B', '7').str.replace('>$20B','21').str.replace('>$1B','2')\n",
    "allocator_data_db['AUM Range'] = allocator_data_db['AUM Range'].str.replace('Not Disclosed', '').str.replace('Not disclosed', '')\n",
    "allocator_data_db.loc[allocator_data_db['AUM Range'] == '', 'AUM Range'] = None\n",
    "allocator_data_db['AUM Range'] = allocator_data_db['AUM Range'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "metadata": {},
   "outputs": [],
   "source": [
    "allocator_data_db.loc[allocator_data_db['AUM Range'] <=0.5, 'AUM Category'] = 'Under $0.5B'\n",
    "allocator_data_db.loc[(allocator_data_db['AUM Range'] >0.5) & (allocator_data_db['AUM Range'] <= 2), 'AUM Category'] = '$0.5B - $2B' \n",
    "allocator_data_db.loc[(allocator_data_db['AUM Range'] >2) & (allocator_data_db['AUM Range'] <=5), 'AUM Category'] = '$2B - $5B'\n",
    "allocator_data_db.loc[(allocator_data_db['AUM Range'] >5) & (allocator_data_db['AUM Range'] <=10), 'AUM Category'] = '$5B - $10B'\n",
    "allocator_data_db.loc[(allocator_data_db['AUM Range'] >10) , 'AUM Category'] = 'Over $10B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "metadata": {},
   "outputs": [],
   "source": [
    "EandF_AUM_Matching_pairs = []\n",
    "Pension_AUM_Matching_pairs = []\n",
    "\n",
    "for allocator1 in EandF_allocators:\n",
    "    for allocator2 in EandF_allocators:\n",
    "        if allocator1 != allocator2: \n",
    "            allocator1_AUM = allocator_data_db[allocator_data_db['Contact'] ==allocator1]['AUM Category'].values[0]\n",
    "            allocator2_AUM = allocator_data_db[allocator_data_db['Contact'] ==allocator2]['AUM Category'].values[0]\n",
    "            \n",
    "\n",
    "            # if allocator1_AUM in ['Under $0.5B'] and  allocator2_AUM in ['Under $0.5B'] :\n",
    "            #     EandF_AUM_Matching_pairs.append((allocator1, allocator2))\n",
    "\n",
    "            # elif allocator1_AUM in [ '$0.5B - $2B'] and  allocator2_AUM in [ '$0.5B - $2B'] :\n",
    "            #     EandF_AUM_Matching_pairs.append((allocator1, allocator2))\n",
    "\n",
    "            if allocator1_AUM in ['Over $10B'] and  allocator2_AUM in ['Over $10B'] :\n",
    "                EandF_AUM_Matching_pairs.append((allocator1, allocator2))\n",
    "\n",
    "            # if allocator1_AUM in ['Under $0.5B', '$0.5B - $2B',  '$5B - $10B'] and  allocator2_AUM in['Under $0.5B', '$0.5B - $2B',  '$5B - $10B'] :\n",
    "            #     EandF_AUM_Matching_pairs.append((allocator1, allocator2))\n",
    "            # elif allocator1_AUM in ['$2B - $5B', '$5B - $10B', 'Over $10B'] and  allocator2_AUM in ['$2B - $5B', '$5B - $10B', 'Over $10B']:\n",
    "            #     EandF_AUM_Matching_pairs.append((allocator1, allocator2))\n",
    "\n",
    "\n",
    "for allocator1 in Pension_allocators:\n",
    "    for allocator2 in Pension_allocators:\n",
    "        if allocator1 != allocator2: \n",
    "            allocator1_AUM = allocator_data_db[allocator_data_db['Contact'] ==allocator1]['AUM Category'].values[0]\n",
    "            allocator2_AUM = allocator_data_db[allocator_data_db['Contact'] ==allocator2]['AUM Category'].values[0]\n",
    "            \n",
    "            if allocator1_AUM in ['Under $0.5B', '$0.5B - $2B',  '$5B - $10B'] and  allocator2_AUM in['Under $0.5B', '$0.5B - $2B',  '$5B - $10B'] :\n",
    "                Pension_AUM_Matching_pairs.append((allocator1, allocator2))\n",
    "            elif allocator1_AUM in ['$2B - $5B', '$5B - $10B', 'Over $10B'] and  allocator2_AUM in ['$2B - $5B', '$5B - $10B', 'Over $10B']:\n",
    "                Pension_AUM_Matching_pairs.append((allocator1, allocator2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAonly_table_assignments = {}\n",
    "MAonly_table_assignments['Session 4'] = meeting_assignments['Session 4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Check that the assignments are correct**\n",
    "##### - F/ A ratios\n",
    "##### - people seated in the correct groupings \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "qa_asset_theme_dict = {}\n",
    "\n",
    "for session, tables in MAonly_table_assignments.items():\n",
    "\n",
    "    print()\n",
    "    updated_tables = {}\n",
    "    \n",
    "    for table, names in tables.items():\n",
    "\n",
    "        allocator_names = [name for name in names if name.endswith('A')]\n",
    "        fund_names = [name for name in names if name.endswith('F')]\n",
    "\n",
    "        updated_allocator_names = [(allocator_data_db.loc[allocator_data_db['Contact'] == name, '*Description of Organization'].iloc[0] , allocator_data_db.loc[allocator_data_db['Contact'] == name, 'AUM Category'].iloc[0])\n",
    "                         if  name in allocator_data_db['Contact'].values else name\n",
    "                         for name in allocator_names]\n",
    "\n",
    "        updated_fund_names = [fund_data_db.loc[fund_data_db['Contact'] == name, 'AUM Range'].iloc[0]\n",
    "                         if  name in fund_data_db['Contact'].values else name\n",
    "                         for name in fund_names]\n",
    "\n",
    "        updated_tables[table] = updated_fund_names + updated_allocator_names\n",
    "    \n",
    "    qa_asset_theme_dict[session] = updated_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Which preferences were satisfied here? \n",
    "##### - No funds or allocators are sitting together so none are satisfied here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary to store pair counts # \n",
    "MA_pair_counts = {}\n",
    "for pair in pair_count_list:\n",
    "    for table in MAonly_table_assignments['Session 4']:\n",
    "        assignments = MAonly_table_assignments['Session 4'][table]\n",
    "        if pair[0] in assignments and pair[1] in assignments:\n",
    "            MA_pair_counts[pair] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "metadata": {},
   "outputs": [],
   "source": [
    "MA_satisfied_fund_assetclass_pairs =list(set([pair for pair in fund_assetclass_matches if pair in MA_pair_counts  or (pair[1], pair[0]) in MA_pair_counts]))\n",
    "MA_satisfied_fund_aum_pairs =  list(set([pair for pair in fund_aum_matches if pair in MA_pair_counts  or (pair[1], pair[0]) in MA_pair_counts]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1083,
   "metadata": {},
   "outputs": [],
   "source": [
    "if set(MA_pair_counts.values()) != {1}:\n",
    "    raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Took 38.67 minutes from start to here\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "print(f'This Took {round((end_time - start_time)/60, 2)} minutes from start to here')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Other Sessions\n",
    "- removing table_session pairs, any relevant constraints, and objectives  this solves almost immediately \n",
    "- adding in table session pairs and the constriant that assigns the values to these variables this takes _ to solve "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up LP Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define LP Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1085,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_sessions = [session for session in [i for i in range(1, number_sessions+1)] if session != MAonly_session and session != lunch_session and session not in dive_deeper_sessions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1086,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_table_assignments = {}\n",
    "for session in main_sessions:\n",
    "    main_table_assignments[f'Session {session}'] = meeting_assignments[f'Session {session}'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary to store pair counts # \n",
    "main_pair_counts = {}\n",
    "for pair in pair_count_list:\n",
    "    main_pair_counts[pair] = 0\n",
    "    for session in main_sessions: \n",
    "        for table in main_table_assignments[f'Session {session}']:\n",
    "            assignments = main_table_assignments[f'Session {session}'][table]\n",
    "            if pair[0] in assignments and pair[1] in assignments:\n",
    "                main_pair_counts[pair] += 1\n",
    "main_pair_counts = {k: v for k, v in main_pair_counts.items() if v>0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 1440, 2: 220, 3: 2})"
      ]
     },
     "execution_count": 1089,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(main_pair_counts.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_satisfied_allocator_pref_pairs = list(set([pair for pair in allocator_pref_pairs if pair in main_pair_counts or (pair[1], pair[0]) in main_pair_counts]))\n",
    "main_satisfied_fund_pref_pairs =list(set([pair for pair in fund_pref_pairs if pair in main_pair_counts or (pair[1], pair[0]) in main_pair_counts]))\n",
    "main_satisfied_mutual_pref_pairs = list(set([pair for pair in mutual_pref_pairs if pair in main_pair_counts  or (pair[1], pair[0]) in main_pair_counts]))\n",
    "main_satisfied_fund_assetclass_pairs = list(set([pair for pair in fund_assetclass_matches if pair in main_pair_counts  or (pair[1], pair[0]) in main_pair_counts]))\n",
    "main_satisfied_fund_aum_pairs = list(set([pair for pair in fund_aum_matches if pair in main_pair_counts  or (pair[1], pair[0]) in main_pair_counts]))\n",
    "main_satisfied_allocator_nopref_pairs = list(set([pair for pair in allocator_no_pref_pairs if pair in main_pair_counts  or (pair[1], pair[0]) in main_pair_counts]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LUNCH\n",
      "13.59 % Allocator prefs satsified  in Lunch\n",
      "4.9 % Fund prefs satsified in Lunch\n",
      "8.33 % Mutual prefs satsified in Lunch\n",
      "0.0 % No prefs satsified  in Lunch\n",
      "MAIN\n",
      "60.52 % Allocator prefs satsified  in Main\n",
      "50.98 % Fund prefs satsified in Main\n",
      "91.67 % Mutual prefs satsified in Main\n",
      "0.0 % No prefs satsified  in Main\n"
     ]
    }
   ],
   "source": [
    "print('LUNCH')\n",
    "if  len(allocator_pref_pairs) > 0:\n",
    "    print(round((len(set(lunch_satisfied_allocator_pref_pairs)) / len(allocator_pref_pairs) )*100, 2) , '% Allocator prefs satsified  in Lunch')\n",
    "if  len(fund_pref_pairs) > 0:\n",
    "    print(round((len(set(lunch_satisfied_fund_pref_pairs)) / len(fund_pref_pairs))*100, 2) , '% Fund prefs satsified in Lunch')\n",
    "if  len(mutual_pref_pairs) > 0:\n",
    "    print(round((len(set(lunch_satisfied_mutual_pref_pairs)) / len(mutual_pref_pairs))*100, 2) , '% Mutual prefs satsified in Lunch')\n",
    "if  len(allocator_no_pref_pairs) > 0:\n",
    "    print(round((len(set(lunch_satisfied_allocator_nopref_pairs)) / len(allocator_no_pref_pairs))*100, 2), '% No prefs satsified  in Lunch')\n",
    "\n",
    "print('MAIN')\n",
    "if  len(allocator_pref_pairs) > 0:\n",
    "    print(round((len(set(main_satisfied_allocator_pref_pairs)) / len(allocator_pref_pairs) )*100, 2) , '% Allocator prefs satsified  in Main')\n",
    "if  len(fund_pref_pairs) > 0:\n",
    "    print(round((len(set(main_satisfied_fund_pref_pairs)) / len(fund_pref_pairs))*100, 2) , '% Fund prefs satsified in Main')\n",
    "if  len(mutual_pref_pairs) > 0:\n",
    "    print(round((len(set(main_satisfied_mutual_pref_pairs)) / len(mutual_pref_pairs))*100, 2) , '% Mutual prefs satsified in Main')\n",
    "if  len(allocator_no_pref_pairs) > 0:\n",
    "    print(round((len(set(main_satisfied_allocator_nopref_pairs)) / len(allocator_no_pref_pairs))*100, 2), '% No prefs satsified  in Main')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create dictionary with all values! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at pair counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_counts = {}\n",
    "\n",
    "for pair in pair_count_list:\n",
    "    pair_counts[pair] = 0 \n",
    "\n",
    "    if pair in lunch_pair_counts:\n",
    "        pair_counts[pair] += lunch_pair_counts[pair]\n",
    "    if pair in MA_pair_counts:\n",
    "        pair_counts[pair] += MA_pair_counts[pair]\n",
    "    if pair in main_pair_counts:\n",
    "        pair_counts[pair] += main_pair_counts[pair]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 5760, 1: 1699, 2: 285, 3: 6})"
      ]
     },
     "execution_count": 1095,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(pair_counts.values())\n",
    "\n",
    "# print(f'{round((Counter(pair_counts.values())[1]*100 / Counter(pair_counts.values())[1]),1)}% of pairs sat together 1 time')\n",
    "# print(f'{round((Counter(pair_counts.values())[2]*100 / Counter(pair_counts.values())[1]),2)}% of pairs sat together 2 times')\n",
    "# print(f'{round((Counter(pair_counts.values())[3]*100 / Counter(pair_counts.values())[1]),3)}% of pairs sat together 3 times')\n",
    "# print(f'{round((Counter(pair_counts.values())[4]*100 / Counter(pair_counts.values())[1]),4)}% of pairs sat together 4 times')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quality Check for pair counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sort the pair_counts so that they match up with the pair_count_list which creates all the table_session_pair_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1096,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_counts_sorted = {}\n",
    "for pair in pair_counts:\n",
    "    # if the inverse of the pair is in pair counts list swap them \n",
    "    if pair not in pair_count_list:\n",
    "        if (pair[1], pair[0]) in pair_count_list:\n",
    "            pair_counts_sorted[(pair[1], pair[0])] = pair_counts[pair]\n",
    "    elif pair in pair_count_list:\n",
    "        pair_counts_sorted[pair] = pair_counts[pair]\n",
    "\n",
    "pair_counts = pair_counts_sorted\n",
    "\n",
    "# sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check that the number of Funds and Allocators are correct for each\n",
    "- If youre looking at an old rerun it may be incorrect since the updated data determines the table frameworks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this might throw errors if the lunch session was run as a main session  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1099,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session in [i for i in range(1, number_sessions+1) if i!= lunch_session]:\n",
    "\n",
    "    for table in range(1, number_tables_dict[session] + 1):\n",
    "        assignments = meeting_assignments[f'Session {session}'][table]\n",
    "        # print(assignments)\n",
    "        if lunch_session != [] and session == lunch_session:\n",
    "            print(assignments)\n",
    "            assignments = [value for value in list(assignments.values() ) if value != ()]\n",
    "    \n",
    "        assignments =[ item for item in assignments if not item.endswith('_S')]\n",
    "        framework = table_frameworks[f'Session {session}'][f'Table {table}']\n",
    "        if framework.count('A') != sum(1 for item in assignments if item.endswith('_A')):\n",
    "            print('Session', session,'Table', table, 'Allocators')\n",
    "            print('Table Framework Count A:', (framework.count('A')),'Results Count A:', (sum(1 for item in assignments if item.endswith('_A'))) )\n",
    "        if framework.count('F') != sum(1 for item in assignments if item.endswith('_F')):\n",
    "            print('Session', session,'Table', table, 'Funds')\n",
    "            print('Table Framework Count F:', (framework.count('F')),'Results Count F:', (sum(1 for item in assignments if item.endswith('_F'))) )\n",
    "        if framework.count('F') == sum(1 for item in assignments if item.endswith('_F')) and framework.count('A') == sum(1 for item in assignments if item.endswith('_A')):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Are people seated more than one time in a session?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_session_to_list_of_lists(session_data):\n",
    "    result = []\n",
    "    for key, inner_dict in session_data.items():\n",
    "        names = [name for name in inner_dict.values() if isinstance(name, str)]\n",
    "        result.append(names)\n",
    "    return result\n",
    "\n",
    "\n",
    "# Create a Pandas Series\n",
    "for session in range(1, number_sessions+1):\n",
    "    if lunch_session != [] and session == lunch_session: \n",
    "        df = pd.DataFrame(pd.Series([value for sublist in convert_session_to_list_of_lists(meeting_assignments[f'Session {session}']) for value in sublist]).value_counts()).reset_index()\n",
    "\n",
    "    elif session != lunch_session:\n",
    "        df = pd.DataFrame(pd.Series([value for sublist in meeting_assignments[f'Session {session}'].values() for value in sublist]).value_counts()).reset_index()\n",
    "    df = df[df['index']!= 'Empty Seat']\n",
    "    if df[df['count'] >1].shape[0] >0:\n",
    "        to_print = df[df['count'] >1].shape[0]\n",
    "        raise ValueError(f'There are {to_print} names in Session {session} that are seated twice')\n",
    "    #     print(f'There are {(df[df['count'] >1].shape[0])} names in Session {session} that are seated twice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The list of names in session 1 is the same as the set of the list of names in session 1 (duplicates if false): True\n",
      "Length of the set: 145\n",
      "Length of the list: 145\n"
     ]
    }
   ],
   "source": [
    "print('The list of names in session 1 is the same as the set of the list of names in session 1 (duplicates if false):',\n",
    "       len(set([value for sublist in meeting_assignments['Session 1'].values() for value in sublist])) == len(([value for sublist in meeting_assignments['Session 1'].values() for value in sublist])))\n",
    "print(f'Length of the set: {len(set([value for sublist in meeting_assignments['Session 1'].values() for value in sublist]))}\\nLength of the list: {len(([value for sublist in meeting_assignments['Session 1'].values() for value in sublist]))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quality Check for Fully Seated tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tables are fully seated :)\n"
     ]
    }
   ],
   "source": [
    "# QA that all seats are filled\n",
    "qa_count = 0 \n",
    "for i in range(1,number_sessions+1):\n",
    "    session = meeting_assignments[f'Session {i}']\n",
    "    for table in session: \n",
    "        assignments = meeting_assignments[f'Session {i}'][table]\n",
    "        if i == lunch_session:\n",
    "            assignments = [value for value in list(assignments.values() ) if value != ()]\n",
    "        if assignments.count('A') > 0 or assignments.count('F') > 0:\n",
    "            qa_count += 1\n",
    "            print(f\"Session {i} Table {table} not fully seated!\")\n",
    "\n",
    "if qa_count > 0 :\n",
    "    raise ValueError('Tables are not fully seated')\n",
    "else:\n",
    "    print('All tables are fully seated :)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pair Counts dfs\n",
    "\n",
    "All sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1103,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df = pd.DataFrame.from_dict(Counter(pair_counts.values()), orient='index', columns=['Count']).reset_index()\n",
    "counts_df.columns = ['# Times Sat Together', '# Occurrences']\n",
    "counts_df= counts_df.sort_values(by ='# Times Sat Together')\n",
    "counts_df['% of Total Occurrences'] = round(((counts_df['# Occurrences'] / (counts_df['# Occurrences'].sum())) * 100),2)\n",
    "\n",
    "# Convert the dictionary to a list of dictionaries\n",
    "data_list = [{'Person 1': pair[0], 'Person 2': pair[1], 'Number Times sat together': value} for pair, value in pair_counts.items()]\n",
    "\n",
    "# Create a DataFrame from the list\n",
    "pair_counts_matrix = pd.DataFrame(data_list)\n",
    "\n",
    "# Format back to Correct Name (not contact format)\n",
    "for col in ['Person 1', 'Person 2']:\n",
    "    # remove underscore replace with space\n",
    "    pair_counts_matrix[col] = pair_counts_matrix[col].str.replace('_', ' ')\n",
    "    #Captialize\n",
    "    pair_counts_matrix[col] = pair_counts_matrix[col].str.title()\n",
    "\n",
    "    # replace \" F\" with \"(F)\" and ' A' with (A) in all columns # use positive lookback assertion\n",
    "    pair_counts_matrix = pair_counts_matrix.replace({'(?<= )F$': ' (F)'}, regex=True)\n",
    "    pair_counts_matrix = pair_counts_matrix.replace({'(?<= )A$': ' (A)'}, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without lunch session (8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1104,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_counts_no8 = {}\n",
    "\n",
    "for pair in pair_count_list:\n",
    "\n",
    "    pair_counts_no8[pair] = 0 \n",
    "    if pair in MA_pair_counts:\n",
    "        pair_counts_no8[pair] += MA_pair_counts[pair]\n",
    "    if pair in main_pair_counts:\n",
    "        pair_counts_no8[pair] += main_pair_counts[pair]\n",
    "\n",
    "\n",
    "counts_no8_df = pd.DataFrame.from_dict(Counter(pair_counts_no8.values()), orient='index', columns=['Count']).reset_index()\n",
    "counts_no8_df.columns = ['# Times Sat Together', '# Occurrences']\n",
    "counts_no8_df= counts_df.sort_values(by ='# Times Sat Together')\n",
    "counts_no8_df['% of Total Occurrences'] = round(((counts_no8_df['# Occurrences'] / (counts_no8_df['# Occurrences'].sum())) * 100),2)\n",
    "\n",
    "# Convert the dictionary to a list of dictionaries\n",
    "data_list = [{'Person 1': pair[0], 'Person 2': pair[1], 'Number Times sat together': value} for pair, value in pair_counts_no8.items()]\n",
    "\n",
    "# Create a DataFrame from the list\n",
    "pair_counts_matrix_no8 = pd.DataFrame(data_list)\n",
    "\n",
    "\n",
    "# Format back to Correct Name (not contact format)\n",
    "for col in ['Person 1', 'Person 2']:\n",
    "    # remove underscore replace with space\n",
    "    pair_counts_matrix_no8[col] = pair_counts_matrix_no8[col].str.replace('_', ' ')\n",
    "    #Captialize\n",
    "    pair_counts_matrix_no8[col] = pair_counts_matrix_no8[col].str.title()\n",
    "\n",
    "    # replace \" F\" with \"(F)\" and ' A' with (A) in all columns # use positive lookback assertion\n",
    "    pair_counts_matrix_no8 = pair_counts_matrix_no8.replace({'(?<= )F$': ' (F)'}, regex=True)\n",
    "    pair_counts_matrix_no8 = pair_counts_matrix_no8.replace({'(?<= )A$': ' (A)'}, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just main sessions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1105,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_main_df = pd.DataFrame.from_dict(Counter(main_pair_counts.values()), orient='index', columns=['Count']).reset_index()\n",
    "counts_main_df.columns = ['# Times Sat Together', '# Occurrences']\n",
    "counts_main_df= counts_df.sort_values(by ='# Times Sat Together')\n",
    "counts_main_df['% of Total Occurrences'] = round(((counts_main_df['# Occurrences'] / (counts_main_df['# Occurrences'].sum())) * 100),2)\n",
    "\n",
    "# Convert the dictionary to a list of dictionaries\n",
    "data_list = [{'Person 1': pair[0], 'Person 2': pair[1], 'Number Times sat together': value} for pair, value in main_pair_counts.items()]\n",
    "\n",
    "# Create a DataFrame from the list\n",
    "pair_counts_matrix_main = pd.DataFrame(data_list)\n",
    "\n",
    "\n",
    "# Format back to Correct Name (not contact format)\n",
    "for col in ['Person 1', 'Person 2']:\n",
    "    # remove underscore replace with space\n",
    "    pair_counts_matrix_main[col] = pair_counts_matrix_main[col].str.replace('_', ' ')\n",
    "    #Captialize\n",
    "    pair_counts_matrix_main[col] = pair_counts_matrix_main[col].str.title()\n",
    "\n",
    "    # replace \" F\" with \"(F)\" and ' A' with (A) in all columns # use positive lookback assertion\n",
    "    pair_counts_matrix_main = pair_counts_matrix_main.replace({'(?<= )F$': ' (F)'}, regex=True)\n",
    "    pair_counts_matrix_main = pair_counts_matrix_main.replace({'(?<= )A$': ' (A)'}, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pad the tables and the seats with NA values so that the rest of the code can work: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1106,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change all tables to # instead of Tablce #\n",
    "\n",
    "for session in meeting_assignments:\n",
    "    \n",
    "    if lunch_session != [] and session != lunch_session: \n",
    "        updated_dict = {}\n",
    "        for key, value in meeting_assignments[session].items():\n",
    "            if not isinstance(key, int):\n",
    "                new_key = int(key.split(' ')[-1])\n",
    "                updated_dict[new_key] = value\n",
    "            else:\n",
    "                updated_dict[key] = value\n",
    "        meeting_assignments[session] = updated_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change to tuples rather than lists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1107,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session in range(1, number_sessions+1):\n",
    "        for table in range(1, number_tables_dict[session]+1):\n",
    "            if lunch_session != [] and session != lunch_session:\n",
    "                assignments = meeting_assignments[f'Session {session}'][table]\n",
    "                meeting_assignments[f'Session {session}'][table] = tuple(assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sessions with empty tables \n",
    "\n",
    "# Find the highest number of tables \n",
    "# max_session = max(len(meeting_assignments[f'Session {i}']) for session_tables in meeting_assignments.values())\n",
    "max_session = max(number_tables_dict.values())\n",
    "\n",
    "for i in range (1, number_sessions+1): # meeting assignments\n",
    "    if lunch_session != [] and i != lunch_session:\n",
    "        while len(meeting_assignments[f'Session {i}']) < max_session:\n",
    "            last_table = max(meeting_assignments[f'Session {i}'].keys())\n",
    "            new_table_name = last_table + 1\n",
    "            meeting_assignments[f'Session {i}'][new_table_name] = ()\n",
    "    else:\n",
    "        while len(meeting_assignments[f'Session {i}']) < max_session:\n",
    "            last_table = max(meeting_assignments[f'Session {i}'].keys())\n",
    "            new_table_name = last_table + 1\n",
    "            meeting_assignments[f'Session {i}'][new_table_name] = {}\n",
    "\n",
    "# Pad tables with empty seats\n",
    "for i in range(1, number_sessions+1): # meeting assignments \n",
    "    if lunch_session != [] and i != lunch_session:\n",
    "        tables = meeting_assignments[f'Session {i}']\n",
    "        for table_key, table in tables.items():\n",
    "            while len(table) < max_table_size_dict[i]:\n",
    "                table = table + ('Empty Seat',)\n",
    "            tables[table_key] = table  # update table in dictionary\n",
    "        meeting_assignments[f'Session {i}'] = tables  # update tables for the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sessions with empty seats \n",
    "\n",
    "# Iterate through the dictionary\n",
    "for session, inner_dict in meeting_assignments.items():\n",
    "    updated_inner_dict = {}  # Create a new inner dictionary for the updated values\n",
    "    \n",
    "    for inner_key, inner_value in inner_dict.items():\n",
    "        if isinstance(inner_key, str) and inner_key.startswith('Table '):\n",
    "            # If the inner key starts with 'Table ', extract the integer part\n",
    "            updated_inner_key = int(inner_key.split(' ')[1])\n",
    "        else:\n",
    "            updated_inner_key = inner_key  # Keep the key as is\n",
    "        \n",
    "        updated_inner_dict[updated_inner_key] = inner_value  # Update the inner dictionary\n",
    "    \n",
    "    meeting_assignments[session] = updated_inner_dict  # Update the outer dictionary\n",
    "\n",
    "\n",
    "## Add dictionary for empty tables in session unch\n",
    "\n",
    "if lunch_session != [] :\n",
    "    for table in  meeting_assignments[f'Session {lunch_session}']:\n",
    "        if meeting_assignments[f'Session {lunch_session}'][table] == {}:\n",
    "            meeting_assignments[f'Session {lunch_session}'][table] = {i: () for i in range(1, 10 + 1)}\n",
    "\n",
    "\n",
    "# Lunch session empty seats \n",
    "if lunch_session != [] :\n",
    "    for table in meeting_assignments[f'Session {lunch_session}']:\n",
    "        meeting_assignments[f'Session {lunch_session}'][table] = {key: 'Empty Seat' if value == () else value for key, value in meeting_assignments[f'Session {lunch_session}'][table].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Meeting Assignments Dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match the formatting of all of them with the formatting of lunch!! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove lunch from meeting assignments - I want to create that df sep and then glue it on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1110,
   "metadata": {},
   "outputs": [],
   "source": [
    "meeting_assignments_lunch = meeting_assignments['Session 8']\n",
    "meeting_assignments_main =  {key: value for key, value in meeting_assignments.items() if key != 'Session 8'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No clue why I'm geting extra seats but here we are with a fix ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1111,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session in range(1, 8):\n",
    "\n",
    "    for table in [19,20]:\n",
    "        if len(meeting_assignments_main[f'Session {session}'][table]) >10:\n",
    "            print(session)\n",
    "            print(len(meeting_assignments_main[f'Session {session}'][table]))\n",
    "            print(meeting_assignments_main[f'Session {session}'][table])\n",
    "            if  set(meeting_assignments_main[f'Session {session}'][table]) == {'Empty Seat'}:\n",
    "                meeting_assignments_main[f'Session {session}'][table] = tuple(['Empty Seat' for i in range(1, max_table_size_dict[session])])\n",
    "            # raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for session in range (1, 8):\n",
    "    for table in range(1, number_tables_dict[session]+1):\n",
    "        assignments = list(meeting_assignments_main[f'Session {session}'][table])\n",
    "        print(len(assignments))\n",
    "        if len(assignments) == 9:\n",
    "            assignments.append('Empty Seat')\n",
    "            meeting_assignments_main[f'Session {session}'][table] = tuple(assignments)\n",
    "        print(len(assignments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format the Main sessions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1137,
   "metadata": {},
   "outputs": [],
   "source": [
    "meeting_assignments_main_df = pd.DataFrame.from_dict({(i, j): meeting_assignments_main[i][j] for i in meeting_assignments_main.keys() for j in meeting_assignments_main[i].keys()},\n",
    "                            orient='index')\n",
    "\n",
    "# Name Sessions \n",
    "sessions_range = [f'Session {i}' for i in [i for i in range(1, number_sessions) if i != lunch_session] for _ in range(max(number_tables_dict.values()) )]\n",
    "meeting_assignments_main_df['Session'] = sessions_range\n",
    "\n",
    "table_range = []\n",
    "\n",
    "for i in [i for i in range(1, number_sessions+1) if i != lunch_session]:\n",
    "    for j in range(1, max(number_tables_dict.values()) + 1):\n",
    "        table_range.append(j)\n",
    "        \n",
    "# Name Tables \n",
    "meeting_assignments_main_df['Table'] = table_range\n",
    "\n",
    "# Set index to session and table \n",
    "meeting_assignments_main_df.set_index(['Session','Table'], inplace = True)\n",
    "\n",
    "# Replace _ with space\n",
    "meeting_assignments_main_df = meeting_assignments_main_df.applymap(        \n",
    "    lambda x: x.replace('_', ' ') if isinstance(x, str) else x)\n",
    "\n",
    "# Capitalize Names \n",
    "meeting_assignments_main_df = meeting_assignments_main_df.applymap(lambda x: x.title() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Format To Match IR Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace \" F\" with \"(F)\" in all columns # use positive lookback assertion\n",
    "meeting_assignments_main_df = meeting_assignments_main_df.replace({'(?<= )F$': ' (F)'}, regex=True)\n",
    "meeting_assignments_main_df = meeting_assignments_main_df.replace({'(?<= )A$': ' (A)'}, regex=True)\n",
    "meeting_assignments_main_df = meeting_assignments_main_df.replace({'(?<= )S$': ' (S)'}, regex=True)\n",
    "# Replace \"Empty Seat\" with Z so that it goes to the end \n",
    "meeting_assignments_main_df= meeting_assignments_main_df.replace('Empty Seat', '(Z)')\n",
    "\n",
    "\n",
    "\n",
    "meeting_assignments_main_df = meeting_assignments_main_df.T.stack().reset_index()\n",
    "meeting_assignments_main_df = meeting_assignments_main_df.drop(columns = ['level_0']).sort_values(by  = [\"Table\"])\n",
    "meeting_assignments_main_df = meeting_assignments_main_df.set_index('Table')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sort by Table and format empty seats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorts the (A) and (F) in the dataframe\n",
    "def sort_group_by_marker(group):\n",
    "    group[['col1', 'col2']] = group[['Session 2', 'Session 4']].apply(lambda x: x.str[-3:])\n",
    "    group = group.sort_values(by=['col1', 'col2'], ascending=True)\n",
    "    group = group.drop(['col1', 'col2'], axis=1)\n",
    "    return group\n",
    "\n",
    "\n",
    "meeting_assignments_main_df = meeting_assignments_main_df.reset_index()\n",
    "\n",
    "# apply sorting function to each group within 'Table' column\n",
    "meeting_assignments_main_df = meeting_assignments_main_df.groupby('Table', group_keys=False).apply(sort_group_by_marker)\n",
    "\n",
    "# reset index and drop group index level#\n",
    "meeting_assignments_main_df= meeting_assignments_main_df.set_index('Table')\n",
    "meeting_assignments_main_df= meeting_assignments_main_df.replace('(Z)', '       -       ')\n",
    "\n",
    "meeting_assignments_main_df = meeting_assignments_main_df.fillna( '       -       ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format the Lunch DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "metadata": {},
   "outputs": [],
   "source": [
    "meeting_assignments_lunch_df = pd.DataFrame.from_dict({(i, j): meeting_assignments_lunch[i][j] for i in meeting_assignments_lunch.keys() for j in meeting_assignments_lunch[i].keys()},\n",
    "                            orient='index')\n",
    "\n",
    "# Name Sessions \n",
    "meeting_assignments_lunch_df['Session'] = lunch_session\n",
    "\n",
    "table_range = [i for i in range(1, number_tables_dict[lunch_session]+1)]\n",
    "\n",
    "meeting_assignments_lunch_df = meeting_assignments_lunch_df.reset_index().rename(columns = {'index':'(table,seat)', 0:f'Session {lunch_session}'})\n",
    "\n",
    "meeting_assignments_lunch_df['Table'] = meeting_assignments_lunch_df['(table,seat)'].apply(lambda x: x[0])\n",
    "meeting_assignments_lunch_df['Seat'] = meeting_assignments_lunch_df['(table,seat)'].apply(lambda x: x[1])\n",
    "\n",
    "meeting_assignments_lunch_df = meeting_assignments_lunch_df.drop(columns =['(table,seat)', 'Session'] )\n",
    "\n",
    "\n",
    "# Replace _ with space\n",
    "meeting_assignments_lunch_df = meeting_assignments_lunch_df.applymap(        \n",
    "    lambda x: x.replace('_', ' ') if isinstance(x, str) else x)\n",
    "\n",
    "# Capitalize Names \n",
    "meeting_assignments_lunch_df = meeting_assignments_lunch_df.applymap(lambda x: x.title() if isinstance(x, str) else x)\n",
    "\n",
    "\n",
    "# replace \" F\" with \"(F)\" in all columns # use positive lookback assertion\n",
    "meeting_assignments_lunch_df = meeting_assignments_lunch_df.replace({'(?<= )F$': ' (F)'}, regex=True)\n",
    "meeting_assignments_lunch_df = meeting_assignments_lunch_df.replace({'(?<= )A$': ' (A)'}, regex=True)\n",
    "meeting_assignments_lunch_df = meeting_assignments_lunch_df.replace({'(?<= )S$': ' (S)'}, regex=True)\n",
    "# Replace \"Empty Seat\" with Z so that it goes to the end \n",
    "meeting_assignments_lunch_df= meeting_assignments_lunch_df.replace('Empty Seat', '(Z)')\n",
    "\n",
    "meeting_assignments_lunch_df= meeting_assignments_lunch_df.replace('(Z)', '       -       ')\n",
    "meeting_assignments_lunch_df = meeting_assignments_lunch_df.fillna( '       -       ')\n",
    "\n",
    "meeting_assignments_lunch_df = meeting_assignments_lunch_df.set_index(['Table'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1142,
   "metadata": {},
   "outputs": [],
   "source": [
    "meeting_assignments_df = pd.concat([meeting_assignments_main_df, meeting_assignments_lunch_df.drop(columns= 'Seat')], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Use this if you need it to search for a case insensitive name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for an element starting with \"lisa\" (case-insensitive)\n",
    "pattern = re.compile(r'^susan_chen', re.IGNORECASE)\n",
    "matching_elements = [element for element in funds if pattern.match(element)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Preferences dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Raw Preferences by F/A**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1143,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_prefs_for_funds_dict = {}\n",
    "\n",
    "for fund in funds:\n",
    "    prefs_for_fund = []\n",
    "    for allocator in allocators:\n",
    "\n",
    "        if allocator_prefs_dict[allocator] != None and fund in allocator_prefs_dict[allocator]:\n",
    "            prefs_for_fund.append(allocator)\n",
    "        \n",
    "    raw_prefs_for_funds_dict[fund] = prefs_for_fund\n",
    "\n",
    "\n",
    "raw_prefs_for_allocators_dict = {}\n",
    "for allocator in allocators:\n",
    "    prefs_for_allocator = []\n",
    "    for fund in funds:\n",
    "        if fund_prefs_dict[fund] != None and  allocator in fund_prefs_dict[fund] :\n",
    "            prefs_for_allocator.append(fund)\n",
    "    raw_prefs_for_allocators_dict[allocator] = prefs_for_allocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad with NA values\n",
    "max_length = max(len(value) for value in raw_prefs_for_funds_dict.values())\n",
    "\n",
    "for fund in raw_prefs_for_funds_dict:  \n",
    "    number_padded_values = (max_length - len(raw_prefs_for_funds_dict[fund]))\n",
    "    raw_prefs_for_funds_dict[fund].extend([' ' for i in range(1,number_padded_values+1)])\n",
    "\n",
    "max_length = max(len(value) for value in raw_prefs_for_allocators_dict.values())\n",
    "\n",
    "for allocator in raw_prefs_for_allocators_dict:  \n",
    "    number_padded_values = (max_length - len(raw_prefs_for_allocators_dict[allocator]))\n",
    "    raw_prefs_for_allocators_dict[allocator].extend([' ' for i in range(1,number_padded_values+1)])\n",
    "\n",
    "# Revert from Contact Form\n",
    "raw_prefs_for_funds_dict = {key[:-2].replace('_', ' ').title(): value for key, value in raw_prefs_for_funds_dict.items()}\n",
    "raw_prefs_for_funds_dict = {key: [value[:-2].replace('_', ' ').title() for value in values] for key, values in raw_prefs_for_funds_dict.items()}\n",
    "\n",
    "raw_prefs_for_allocators_dict = {key[:-2].replace('_', ' ').title(): value for key, value in raw_prefs_for_allocators_dict.items()}\n",
    "raw_prefs_for_allocators_dict = {key: [value[:-2].replace('_', ' ').title() for value in values] for key, values in raw_prefs_for_allocators_dict.items()}\n",
    "\n",
    "# Create Dfs \n",
    "raw_prefs_A_df = pd.DataFrame(raw_prefs_for_allocators_dict).T\n",
    "raw_prefs_F_df = pd.DataFrame(raw_prefs_for_funds_dict).T\n",
    "\n",
    "# Add column names \n",
    "raw_prefs_A_df.columns =  [f'Manager {i+1}' for i in range(len(raw_prefs_A_df.columns))]\n",
    "raw_prefs_F_df.columns =  [f'Allocator {i+1}' for i in range(len(raw_prefs_F_df.columns))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Satisfied_prefs list** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1145,
   "metadata": {},
   "outputs": [],
   "source": [
    "satisfied_mutual_prefs = main_satisfied_mutual_pref_pairs + lunch_satisfied_mutual_pref_pairs \n",
    "satisfied_mutual_prefs = list(set(satisfied_mutual_prefs))\n",
    "\n",
    "satisfied_A_prefs = list(set(main_satisfied_allocator_pref_pairs + lunch_satisfied_allocator_pref_pairs ))\n",
    "\n",
    "satisfied_F_prefs = list(set(main_satisfied_fund_pref_pairs + lunch_satisfied_fund_pref_pairs ))\n",
    "\n",
    "allocator_no_pref_pairs_sat_together =list(set(lunch_satisfied_allocator_nopref_pairs + main_satisfied_allocator_nopref_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.52 % Hit Rate for Allocator Preferences\n",
      "55.88 % Hit Rate for Fund Preferences\n",
      "100.0 % Hit Rate for Mutual Preferences\n",
      "0.0 % Hit Rate for Allocator NO Preferences\n",
      "     Want this ^ to be as low as possible\n"
     ]
    }
   ],
   "source": [
    "print(f\"{round(((len(satisfied_A_prefs)/len(allocator_pref_pairs))*100),2)} % Hit Rate for Allocator Preferences\")\n",
    "print(f\"{round(((len(satisfied_F_prefs)/len(fund_pref_pairs))*100),2)} % Hit Rate for Fund Preferences\")\n",
    "print(f\"{round(((len(satisfied_mutual_prefs)/len(mutual_pref_pairs))*100),2)} % Hit Rate for Mutual Preferences\")\n",
    "print(f\"{round(((len(allocator_no_pref_pairs_sat_together)/len(allocator_no_pref_pairs))*100),2)} % Hit Rate for Allocator NO Preferences\")\n",
    "print('     Want this ^ to be as low as possible')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate hit rates\n",
    "hit_rate_allocator = round((len(satisfied_A_prefs) / len(allocator_pref_pairs)) * 100, 2)\n",
    "hit_rate_fund = round((len(satisfied_F_prefs) / len(fund_pref_pairs)) * 100, 2)\n",
    "hit_rate_mutual = round((len(satisfied_mutual_prefs) / len(mutual_pref_pairs)) * 100, 2)\n",
    "hit_rate_allocator_no_pref = round((len(allocator_no_pref_pairs_sat_together) / len(allocator_no_pref_pairs)) * 100, 2)\n",
    "\n",
    "# Create DataFrame\n",
    "data = {\n",
    "    \"Hit Rate for Allocator Prefs\": [hit_rate_allocator],\n",
    "    \"Hit Rate for Fund Prefs\": [hit_rate_fund],\n",
    "    \"Hit Rate for Mutual Prefs\": [hit_rate_mutual],\n",
    "    \"Hit Rate for Allocator NO Prefs\": [hit_rate_allocator_no_pref],\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(data)\n",
    "\n",
    "summary_df =summary_df.T.reset_index().rename(columns = {'index':'Summary Stat', 0: 'Value'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  **satisfied_prefs dictionary** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary\n",
    "satisfied_prefs = {}\n",
    "\n",
    "# Add satisfied fund preferences to the dictionary \n",
    "for F_pref, A_pref in satisfied_F_prefs:\n",
    "    # Check if the key (ending in 'F') is already in the dictionary\n",
    "    if F_pref in satisfied_prefs:\n",
    "        satisfied_prefs[F_pref].append(A_pref)\n",
    "    else:\n",
    "        # If the key is not in the dictionary, create a new list with the 'A' preference\n",
    "        satisfied_prefs[F_pref] = [A_pref]\n",
    "\n",
    "# Add satisfied allocator preferences to the dictionary \n",
    "for F_pref, A_pref in satisfied_A_prefs:\n",
    "    # Check if the key (ending in 'A') is already in the dictionary\n",
    "    if A_pref in satisfied_prefs:\n",
    "        satisfied_prefs[A_pref].append(F_pref)\n",
    "    else:\n",
    "        # If the key is not in the dictionary, create a new list with the 'A' preference\n",
    "        satisfied_prefs[A_pref] = [F_pref]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add the people who didnt have prefs or that had none satisfied "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1149,
   "metadata": {},
   "outputs": [],
   "source": [
    "for contact in attendees:\n",
    "    if contact not in satisfied_prefs:\n",
    "        satisfied_prefs[contact] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create dictionaries for companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Contact tab in the fund and allocator database data \n",
    "fund_df_db['Contact'] =fund_df_db['FirstName'].str.lower() + '_' + fund_df_db['LastName'].str.lower() + '_F'\n",
    "allocator_df_db['Contact'] =allocator_df_db['FirstName'].str.lower() + '_' + allocator_df_db['LastName'].str.lower() + '_A'\n",
    "\n",
    "# Create Company dictionaries\n",
    "fund_company_dict = dict(zip(fund_df_db['Contact'].tolist(), fund_df_db['Company'].tolist()))\n",
    "allocator_company_dict = dict(zip(allocator_df_db['Contact'].tolist(), allocator_df_db['Company'].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **unsatisfied_prefs list** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1151,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsatisfied_F_prefs = []\n",
    "for pair in fund_pref_pairs:\n",
    "    if pair not in satisfied_F_prefs:\n",
    "        unsatisfied_F_prefs.append(pair)\n",
    "\n",
    "if len(set(unsatisfied_F_prefs + satisfied_F_prefs))!= len(set(fund_pref_pairs)):\n",
    "    raise ValueError('Satisfied prefs + Unsatisfied Prefs != all prefs')\n",
    "\n",
    "\n",
    "unsatisfied_A_prefs = []\n",
    "for pair in allocator_pref_pairs:\n",
    "    if pair not in satisfied_A_prefs:\n",
    "        unsatisfied_A_prefs.append(pair)\n",
    "if len(set(unsatisfied_A_prefs)) + len((set(satisfied_A_prefs))) != len(set(allocator_pref_pairs)):\n",
    "    raise ValueError('Satisfied prefs + Unsatisfied Prefs != all prefs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1152,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefs_dict = {**fund_prefs_dict, **allocator_prefs_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1153,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsatisfied_prefs= {}\n",
    "\n",
    "for key in prefs_dict:\n",
    "    if key in satisfied_prefs and key in prefs_dict:\n",
    "        satisfied_values = satisfied_prefs[key]\n",
    "        raw_values = prefs_dict[key]\n",
    "\n",
    "        if raw_values != None:\n",
    "            unsatisfied_values = [value for value in raw_values if value not in satisfied_values]\n",
    "            unsatisfied_prefs[key] = unsatisfied_values\n",
    "        else:\n",
    "            unsatisfied_prefs[key] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Raw Preferences DF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, value in fund_prefs_dict.items():\n",
    "#     if value is None:\n",
    "#         fund_prefs_dict[key] = []\n",
    "\n",
    "# for key, value in allocator_prefs_dict.items():\n",
    "#     if value is None:\n",
    "#         allocator_prefs_dict[key] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_prefs_df_F = pd.DataFrame.from_dict(fund_prefs_dict, orient='index').reset_index()\n",
    "# raw_prefs_df_A = pd.DataFrame.from_dict(allocator_prefs_dict, orient='index').reset_index()\n",
    "\n",
    "# raw_prefs_df = pd.concat([raw_prefs_df_F, raw_prefs_df_A])\n",
    "\n",
    "\n",
    "# # Variablize how many satisfied pref columns there are based on the max \n",
    "# max_length = (max(len(values) for values in allocator_prefs_dict.values()))\n",
    "# raw_prefs_df.columns =  ['Name']+ [f'Preference {i}' for i in range(1, max_length + 1)]\n",
    "\n",
    "# raw_prefs_df['Role'] = raw_prefs_df['Name'].apply(lambda x: 'Manager' if x.endswith('F') else 'Allocator')\n",
    "\n",
    "# # Format Dataframe \n",
    "# # Replace _ with space\n",
    "# raw_prefs_df = raw_prefs_df.applymap(        \n",
    "#     lambda x: x.replace('_', ' ') if isinstance(x, str) else x)\n",
    "\n",
    "# # Capitalize Names \n",
    "# raw_prefs_df= raw_prefs_df.applymap(lambda x: x.title() if isinstance(x, str) else x)\n",
    "\n",
    "# raw_prefs_df = raw_prefs_df.reindex(columns=['Name'] + ['Role'] + ['Company'] + [f'Preference {i}' for i in range(1, max_length + 1)])\n",
    "# # Remove F and A \n",
    "# raw_prefs_df = raw_prefs_df.applymap(lambda x: x[:-2] if isinstance(x, str) and (x.endswith(\" F\") or x.endswith(\" A\")) else x)\n",
    "# # Change None to Empty\n",
    "# raw_prefs_df = raw_prefs_df.fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Satisfied prefs dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# satisfied preferences as dataframe\n",
    "satisfied_prefs_df = pd.DataFrame.from_dict(satisfied_prefs, orient='index').reset_index()\n",
    "\n",
    "# Variablize how many satisfied pref columns there are based on the max \n",
    "max_length = (max(len(values) for values in satisfied_prefs.values()))\n",
    "satisfied_prefs_df.columns =  ['Name']+ [f'Satisfied Pref {i}' for i in range(1, max_length + 1)]\n",
    "\n",
    "satisfied_prefs_df['Role'] = satisfied_prefs_df['Name'].apply(lambda x: 'Manager' if x.endswith('F') else 'Allocator')\n",
    "\n",
    "\n",
    "# Map allocator companies\n",
    "satisfied_prefs_df['Company'] = satisfied_prefs_df['Name'].map(allocator_company_dict)\n",
    "# Map the values that are Nan \n",
    "satisfied_prefs_df.loc[satisfied_prefs_df['Company'].isna(), 'Company'] = satisfied_prefs_df.loc[satisfied_prefs_df['Company'].isna(), 'Name'].map(fund_company_dict)\n",
    "\n",
    "# Format Dataframe \n",
    "# Replace _ with space\n",
    "satisfied_prefs_df = satisfied_prefs_df.applymap(        \n",
    "    lambda x: x.replace('_', ' ') if isinstance(x, str) else x)\n",
    "\n",
    "\n",
    "# Format Dataframe \n",
    "# Replace _ with space\n",
    "satisfied_prefs_df = satisfied_prefs_df.applymap(        \n",
    "    lambda x: x.replace('_', ' ') if isinstance(x, str) else x)\n",
    "\n",
    "# Capitalize Names \n",
    "satisfied_prefs_df= satisfied_prefs_df.applymap(lambda x: x.title() if isinstance(x, str) else x)\n",
    "\n",
    "satisfied_prefs_df = satisfied_prefs_df.reindex(columns=['Name'] + ['Role'] + ['Company'] + [f'Satisfied Pref {i}' for i in range(1, max_length + 1)])\n",
    "# Remove F and A \n",
    "satisfied_prefs_df = satisfied_prefs_df.applymap(lambda x: x[:-2] if isinstance(x, str) and (x.endswith(\" F\") or x.endswith(\" A\")) else x)\n",
    "# Change None to Empty\n",
    "satisfied_prefs_df = satisfied_prefs_df.fillna('')\n",
    "\n",
    "# # Group by the Role and then Sort satisfied prefs\n",
    "# satisfied_prefs_df =  satisfied_prefs_df.groupby('Role', 'Company'\n",
    "#                                         ).apply(\n",
    "#     lambda x: x.sort_values(['Satisfied Pref 2'], ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1155,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add the % satisfied \n",
    "satisfied_prefs_df['% Satisfied'] = np.nan\n",
    "\n",
    "for index, row in satisfied_prefs_df.iterrows():\n",
    "\n",
    "\n",
    "    if row['Role'] == 'Manager':\n",
    "        fund = row['Name'].lower().replace(' ', '_') + '_F'\n",
    "        if fund =='colter_van_domelen_F': fund = 'colter_van domelen_F'\n",
    "        if fund_prefs_dict[fund] != None:\n",
    "            satisfied_prefs_df.loc[index, '% Satisfied'] = (len(satisfied_prefs[fund]) / len(fund_prefs_dict[fund]))\n",
    "        else:\n",
    "            satisfied_prefs_df.loc[index, '% Satisfied'] = 1\n",
    "    elif row['Role'] == 'Allocator':\n",
    "        allocator = row['Name'].lower().replace(' ', '_') + '_A'\n",
    "        if allocator_prefs_dict[allocator] != None:\n",
    "            satisfied_prefs_df.loc[index, '% Satisfied'] = (len(satisfied_prefs[allocator]) / len(allocator_prefs_dict[allocator]))\n",
    "        else:\n",
    "            satisfied_prefs_df.loc[index, '% Satisfied'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# satisfied_prefs_df.to_excel(r\"C:\\Users\\Administrator\\Downloads\\SeatingArrangement_Test.xlsx\", sheet_name='SatisfiedPrefs', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some allocators with prefs have non satisfied\n",
      "Some funds with prefs have non satisfied\n"
     ]
    }
   ],
   "source": [
    "satisfied_prefs_df['Contact'] = satisfied_prefs_df['Name'].str.lower().str.replace(' ', '_')\n",
    "\n",
    "satisfied_prefs_df.loc[satisfied_prefs_df['Role'] == 'Manager', 'Contact'] = satisfied_prefs_df['Contact'] + '_F'\n",
    "satisfied_prefs_df.loc[satisfied_prefs_df['Role'] == 'Allocator', 'Contact'] = satisfied_prefs_df['Contact'] + '_A'\n",
    "\n",
    "\n",
    "funds_no_satisfied_prefs = [name for name in satisfied_prefs if satisfied_prefs[name] == [] and name.endswith('F')]\n",
    "funds_no_satisfied_prefs = [name for name in funds_no_satisfied_prefs if name not in [name for name in fund_prefs_dict if fund_prefs_dict[name] == None]]\n",
    "\n",
    "allocators_no_satisfied_prefs = [name for name in satisfied_prefs if satisfied_prefs[name] == [] and name.endswith('A')]\n",
    "allocators_no_satisfied_prefs = [name for name in allocators_no_satisfied_prefs if name not in [name for name in allocator_prefs_dict if allocator_prefs_dict[name] == None]]\n",
    "\n",
    "if not (allocator_data_db[allocator_data_db['Contact'].isin(allocators_no_satisfied_prefs)]['Preference'].unique() == [None]).all():\n",
    "    print(\"Some allocators with prefs have non satisfied\")\n",
    "\n",
    "if not (fund_data_db[fund_data_db['Contact'].isin(funds_no_satisfied_prefs)]['Preference'].unique() == [None]).all():\n",
    "    print(\"Some funds with prefs have non satisfied\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Unsatisfied prefs dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# satisfied preferences as dataframe\n",
    "unsatisfied_prefs_df = pd.DataFrame.from_dict(unsatisfied_prefs, orient='index').reset_index()\n",
    "\n",
    "# Variablize how many satisfied pref columns there are based on the max \n",
    "max_length = (max(len(values) for values in unsatisfied_prefs.values()))\n",
    "unsatisfied_prefs_df.columns =  ['Name']+ [f'Unsatisfied Pref {i}' for i in range(1, max_length + 1)]\n",
    "\n",
    "# Add role columns\n",
    "unsatisfied_prefs_df['Role'] = unsatisfied_prefs_df['Name'].apply(lambda x: 'Manager' if x.endswith('F') else 'Allocator')\n",
    "\n",
    "# Map allocator companies\n",
    "unsatisfied_prefs_df['Company'] = unsatisfied_prefs_df['Name'].map(allocator_company_dict)\n",
    "# Map the values that are Nan \n",
    "unsatisfied_prefs_df.loc[unsatisfied_prefs_df['Company'].isna(), 'Company'] = unsatisfied_prefs_df.loc[unsatisfied_prefs_df['Company'].isna(), 'Name'].map(fund_company_dict)\n",
    "\n",
    "\n",
    "if not set(unsatisfied_prefs_df['Name'].unique()) == set(attendees):\n",
    "    raise ValueError('not all attendees in this df!')\n",
    "\n",
    "# Format Dataframe \n",
    "# Replace _ with space\n",
    "unsatisfied_prefs_df = unsatisfied_prefs_df.applymap(        \n",
    "    lambda x: x.replace('_', ' ') if isinstance(x, str) else x)\n",
    "\n",
    "\n",
    "unsatisfied_prefs_df = unsatisfied_prefs_df.reindex(columns=['Name'] + ['Role'] + ['Company'] + [f'Unsatisfied Pref {i}' for i in range(1, max_length + 1)])\n",
    "\n",
    "# Capitalize Names \n",
    "unsatisfied_prefs_df= unsatisfied_prefs_df.applymap(lambda x: x.title() if isinstance(x, str) else x)\n",
    "# Remove F and A \n",
    "unsatisfied_prefs_df = unsatisfied_prefs_df.applymap(lambda x: x[:-2] if isinstance(x, str) and (x.endswith(\" F\") or x.endswith(\" A\")) else x)\n",
    "# Change None to Empty\n",
    "unsatisfied_prefs_df = unsatisfied_prefs_df.fillna('')\n",
    "# # Group by the Role and then Sort satisfied prefs\n",
    "# unsatisfied_prefs_df =  unsatisfied_prefs_df.groupby('Role'\n",
    "#                                         ).apply(\n",
    "    # lambda x: x.sort_values(['Unsatisfied Pref 2'], ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unsatisfied_prefs_df.to_excel(r\"C:\\Users\\Administrator\\Downloads\\SeatingArrangement_03282024_unsatisifed.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1158,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add the % satisfied \n",
    "unsatisfied_prefs_df['% Satisfied'] = np.nan\n",
    "\n",
    "for index, row in unsatisfied_prefs_df.iterrows():\n",
    "    if row['Role'] == 'Manager':\n",
    "        fund = row['Name'].lower().replace(' ', '_') + '_F'\n",
    "        if fund == 'colter_van_domelen_F': fund = 'colter_van domelen_F'\n",
    "        if fund_prefs_dict[fund] != None:\n",
    "            unsatisfied_prefs_df.loc[index, '% Satisfied'] = (len(satisfied_prefs[fund]) / len(fund_prefs_dict[fund]))\n",
    "        else:\n",
    "            unsatisfied_prefs_df.loc[index, '% Satisfied'] = 1\n",
    "    elif row['Role'] == 'Allocator':\n",
    "        allocator = row['Name'].lower().replace(' ', '_') + '_A'\n",
    "        if allocator_prefs_dict[allocator] != None:\n",
    "            unsatisfied_prefs_df.loc[index, '% Satisfied'] = (len(satisfied_prefs[allocator]) / len(allocator_prefs_dict[allocator]))\n",
    "        else:\n",
    "            unsatisfied_prefs_df.loc[index, '% Satisfied'] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Allocator No-Pref Pairs Dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None values with empty lists\n",
    "allocator_no_prefs_dict_filtered = {k: v if v is not None else [] for k, v in allocator_no_prefs_dict.items()}\n",
    "\n",
    "# Ensure all values are lists; replace None with empty lists\n",
    "allocator_no_prefs_dict_filtered = {k: (v if isinstance(v, list) else []) for k, v in allocator_no_prefs_dict_filtered.items()}\n",
    "\n",
    "# Find the maximum length of the lists\n",
    "max_len = max(len(lst) for lst in allocator_no_prefs_dict_filtered.values())\n",
    "\n",
    "# Pad lists with NaN values to make them all the same length\n",
    "padded_data = {key: lst + [np.nan] * (max_len - len(lst)) for key, lst in allocator_no_prefs_dict_filtered.items()}\n",
    "\n",
    "# Create a DataFrame\n",
    "allocator_no_prefs_raw_df = pd.DataFrame(padded_data).T\n",
    "allocator_no_prefs_raw_df = allocator_no_prefs_raw_df.reset_index()\n",
    "\n",
    "\n",
    "allocator_no_prefs_raw_df.columns = ['Allocator', 'Manager 1', 'Manager 2', 'Manager 3', 'Manager 4']\n",
    "\n",
    "\n",
    "# Replace _ with space\n",
    "allocator_no_prefs_raw_df = allocator_no_prefs_raw_df.applymap(        \n",
    "    lambda x: x.replace('_', ' ') if isinstance(x, str) else x)\n",
    "\n",
    "\n",
    "# Capitalize Names \n",
    "allocator_no_prefs_raw_df = allocator_no_prefs_raw_df.applymap(lambda x: x.title() if isinstance(x, str) else x)\n",
    "\n",
    "\n",
    "# replace \" F\" with \"(F)\" in all columns # use positive lookback assertion\n",
    "allocator_no_prefs_raw_df = allocator_no_prefs_raw_df.replace({'(?<= )F$': ''}, regex=True)\n",
    "allocator_no_prefs_raw_df = allocator_no_prefs_raw_df.replace({'(?<= )A$': ''}, regex=True)\n",
    "allocator_no_prefs_raw_df = allocator_no_prefs_raw_df.replace({'(?<= )S$': ''}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1160,
   "metadata": {},
   "outputs": [],
   "source": [
    "allocator_no_prefs_dict_satisfied  = {}\n",
    "\n",
    "for key in allocator_no_prefs_dict:\n",
    "    if allocator_no_prefs_dict[key] != None:\n",
    "        allocator_no_prefs_dict_satisfied[key] = []\n",
    "        for value in allocator_no_prefs_dict[key]:\n",
    "            if value == 'colter_van_domelen_F': value = 'colter_van domelen_F'\n",
    "            if pair_counts[(value, key)] > 0 :\n",
    "                # print((value, key))\n",
    "                allocator_no_prefs_dict_satisfied[key].append(value)\n",
    "\n",
    "allocator_no_prefs_dict_satisfied = {k: v for k, v in allocator_no_prefs_dict_satisfied.items() if v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1161,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(allocator_no_prefs_dict_satisfied)>0:\n",
    "    # Replace None values with empty lists\n",
    "    allocator_no_prefs_dict_satisfied = {k: v if v is not None else [] for k, v in allocator_no_prefs_dict_satisfied.items()}\n",
    "\n",
    "    # Ensure all values are lists; replace None with empty lists\n",
    "    allocator_no_prefs_dict_satisfied = {k: (v if isinstance(v, list) else []) for k, v in allocator_no_prefs_dict_satisfied.items()}\n",
    "\n",
    "    # Find the maximum length of the lists\n",
    "    max_len = max(len(lst) for lst in allocator_no_prefs_dict_satisfied.values())\n",
    "\n",
    "    # Pad lists with NaN values to make them all the same length\n",
    "    padded_data = {key: lst + [np.nan] * (max_len - len(lst)) for key, lst in allocator_no_prefs_dict_satisfied.items()}\n",
    "\n",
    "    # Create a DataFrame\n",
    "    allocator_no_prefs_satisfied_df = pd.DataFrame(padded_data).T\n",
    "    allocator_no_prefs_satisfied_df = allocator_no_prefs_satisfied_df.reset_index()\n",
    "\n",
    "\n",
    "    allocator_no_prefs_satisfied_df.columns = ['Allocator', 'Manager 1', 'Manager 2']\n",
    "\n",
    "\n",
    "    # Replace _ with space\n",
    "    allocator_no_prefs_satisfied_df = allocator_no_prefs_satisfied_df.applymap(        \n",
    "        lambda x: x.replace('_', ' ') if isinstance(x, str) else x)\n",
    "\n",
    "\n",
    "    # Capitalize Names \n",
    "    allocator_no_prefs_satisfied_df = allocator_no_prefs_satisfied_df.applymap(lambda x: x.title() if isinstance(x, str) else x)\n",
    "\n",
    "\n",
    "    # replace \" F\" with \"(F)\" in all columns # use positive lookback assertion\n",
    "    allocator_no_prefs_satisfied_df = allocator_no_prefs_satisfied_df.replace({'(?<= )F$': ''}, regex=True)\n",
    "    allocator_no_prefs_satisfied_df = allocator_no_prefs_satisfied_df.replace({'(?<= )A$': ''}, regex=True)\n",
    "    allocator_no_prefs_satisfied_df = allocator_no_prefs_satisfied_df.replace({'(?<= )S$': ''}, regex=True)\n",
    "else:\n",
    "    allocator_no_prefs_satisfied_df = pd.DataFrame(columns = ['Allocator', 'Manager 1', 'Manager 2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Create dataframe showing which matching criteria was applied**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1162,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Session Type': ['Lunch Session', 'Lunch Session', 'Lunch Session', 'Lunch Session', 'Lunch Session', 'Lunch Session', \n",
    "                     \n",
    "                     'Manager/Allocator Only Session', 'Manager/Allocator Only Session', \n",
    "    \n",
    "                     'Main Sessions', 'Main Sessions', 'Main Sessions',  'Main Sessions', 'Main Sessions', 'Main Sessions'],\n",
    "    'Session_Number': [lunch_session, lunch_session, lunch_session, lunch_session, lunch_session, lunch_session, \n",
    "                     \n",
    "                     MAonly_session, MAonly_session, \n",
    "                 \n",
    "                     main_sessions, main_sessions, main_sessions, main_sessions, main_sessions, main_sessions],\n",
    "    'Matching Criteria': ['Mutual Prefs', 'Allocator Prefs','Fund Prefs',   'Allocator No Prefs',   'Aum matches', 'Aum no matches', \n",
    "                                \n",
    "                          'Allocator Institution type match', 'Fund Asset Class Matches', \n",
    "\n",
    "                        \n",
    "                        'Mutual Prefs', 'Allocator Prefs', 'Fund Prefs', 'Allocator No Prefs', 'Aum matches', 'Aum no matches'],\n",
    "    'Weight': [weight_max_aum_matches_lunch, weight_max_fund_prefs_lunch, weight_min_allocator_no_prefs, weight_max_allocator_prefs_lunch, weight_min_aum_no_matches_lunch, weight_max_mutual_prefs_lunch, \n",
    "             weight_max_institution_matches_MA,  weight_max_fund_aum_matches_MA, \n",
    " \n",
    "             weight_max_mutual_prefs, weight_max_allocator_prefs, weight_max_fund_prefs, weight_min_allocator_no_prefs, weight_max_aum_matches, weight_min_aum_no_matches]\n",
    "}\n",
    "\n",
    "model_weights_df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Session Tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1163,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Administrator\\Data-Team\\Seating_Arrangements\\Summer 2024\\lp_summer_2024_running.ipynb Cell 251\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Data-Team/Seating_Arrangements/Summer%202024/lp_summer_2024_running.ipynb#a12404sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m         name \u001b[39m=\u001b[39m name \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_S\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Data-Team/Seating_Arrangements/Summer%202024/lp_summer_2024_running.ipynb#a12404sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m         \u001b[39mif\u001b[39;00m name \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtesting_testing_S\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Data-Team/Seating_Arrangements/Summer%202024/lp_summer_2024_running.ipynb#a12404sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m             company \u001b[39m=\u001b[39m df_excel_staff[df_excel_staff[\u001b[39m'\u001b[39;49m\u001b[39mContact\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m==\u001b[39;49mname ][\u001b[39m'\u001b[39;49m\u001b[39mOrg\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mvalues[\u001b[39m0\u001b[39;49m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Data-Team/Seating_Arrangements/Summer%202024/lp_summer_2024_running.ipynb#a12404sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m             meeting_assignments_df_melted\u001b[39m.\u001b[39mat[index, \u001b[39m'\u001b[39m\u001b[39mCompany\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m company\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Data-Team/Seating_Arrangements/Summer%202024/lp_summer_2024_running.ipynb#a12404sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39m# Remove the marker - leave scheduling conflict marker\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# meeting_assignments_df_reset = meeting_assignments_df.drop(columns = ['Seat']).reset_index()\n",
    "meeting_assignments_df_reset = meeting_assignments_df.reset_index()\n",
    "\n",
    "\n",
    "# Use the melt function to unpivot the DataFrame\n",
    "meeting_assignments_df_melted = pd.melt(meeting_assignments_df_reset, id_vars=['Table'], value_vars=['Session 1', 'Session 2', 'Session 3', 'Session 4', 'Session 5', 'Session 6', 'Session 7'], var_name='Session', value_name='Name')\n",
    "\n",
    "# Reorder the columns\n",
    "meeting_assignments_df_melted = meeting_assignments_df_melted[['Session', 'Table', 'Name']]\n",
    "\n",
    "# Define a custom function to determine the role based on the name\n",
    "def get_role(name):\n",
    "    if '(F)' in name:\n",
    "        return 'Manager'\n",
    "    elif '(A)' in name:\n",
    "        return 'Allocator'\n",
    "    elif '(S)' in name:\n",
    "        return 'Staff'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "# Apply the custom function to create the 'Role' column\n",
    "meeting_assignments_df_melted['Role'] = meeting_assignments_df_melted['Name'].apply(get_role)\n",
    "\n",
    "# Add back in the Company Name#\n",
    "for index, row in meeting_assignments_df_melted.iterrows():\n",
    "    name = row['Name']\n",
    "    # if name.endswith('_S'): name = name[:-2]  # Remove the last three characters \"_SC\"/\n",
    "    name = name.lower()\n",
    "    name = name[:-5]\n",
    "    name = name.replace(' ', '_').strip()\n",
    "\n",
    "\n",
    "\n",
    "    if row['Role'] =='Manager':\n",
    "        name = name + '_F'\n",
    "        if name == 'colter_van_domelen_F': name = 'colter_van domelen_F'\n",
    "        company = fund_data_db[fund_data_db['Contact'] ==name]['Company'].values[0]\n",
    "        meeting_assignments_df_melted.at[index, 'Company'] = company\n",
    "    if row['Role'] =='Allocator':\n",
    "        name = name + '_A'\n",
    "        company = allocator_data_db[allocator_data_db['Contact'] ==name]['Company'].values[0]\n",
    "        meeting_assignments_df_melted.at[index, 'Company'] = company\n",
    "\n",
    "    if row['Role'] == 'Staff':\n",
    "        name = name + '_S'\n",
    "        if name != 'testing_testing_S':\n",
    "            company = df_excel_staff[df_excel_staff['Contact'] ==name ]['Org'].values[0]\n",
    "            meeting_assignments_df_melted.at[index, 'Company'] = company\n",
    "    \n",
    "\n",
    "# Remove the marker - leave scheduling conflict marker\n",
    "meeting_assignments_df_melted['Name'] = meeting_assignments_df_melted['Name'].str.replace(r'\\(A\\)|\\(F\\)||\\(S\\)', '', regex=True)\n",
    "\n",
    "# # Add host information\n",
    "# meeting_assignments_df_melted['HOST'] = np.where(meeting_assignments_df_melted['Role'].isin(['Manager', 'Allocator']), True, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Institution Type and AUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in meeting_assignments_df_melted.iterrows():\n",
    "    name = row['Name']\n",
    "    name = name.strip().lower().replace(' ', '_')\n",
    "\n",
    "\n",
    "    # name = name.replace(' ', '_').replace('_(a)', '_A').replace('_(f)', '_F').replace('_(s)', '_S')\n",
    "    # print(name)\n",
    "\n",
    "    if name != '-':\n",
    "\n",
    "        if row['Role'] == 'Allocator':\n",
    "            name = name + '_A'\n",
    "            allocator_inst_type = allocator_data_db[allocator_data_db['Contact'] == name]['Description Of Organization'].values[0]\n",
    "            allocator_aum = allocator_data_db[allocator_data_db['Contact'] == name]['AUM Range'].values[0]\n",
    "            meeting_assignments_df_melted.at[index, 'Description Of Organization'] = allocator_inst_type\n",
    "            meeting_assignments_df_melted.at[index, 'AUM Range'] = allocator_aum\n",
    "        elif row['Role'] == \"Manager\":\n",
    "            name = name + '_F'\n",
    "            if name == 'colter_van_domelen_F': name = 'colter_van domelen_F'\n",
    "            manager_aum = fund_data_db[fund_data_db['Contact'] == name]['AUM Range'].values[0]\n",
    "            meeting_assignments_df_melted.at[index, 'AUM Range'] = manager_aum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary to store pair counts # \n",
    "lunch_table_pair_counts = {}\n",
    "for pair in pair_count_list:\n",
    "    for table in lunch_table_assignments['Session 8']:\n",
    "        assignments = list(lunch_table_assignments['Session 8'][table].values())\n",
    "        if pair[0] in assignments and pair[1] in assignments:\n",
    "            lunch_table_pair_counts[pair] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1168,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in allocator_no_pref_pairs:\n",
    "    if pair in lunch_table_pair_counts:\n",
    "        print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meeting_assignments_df_melted[(meeting_assignments_df_melted['Session'] == 'Session 4') & (meeting_assignments_df_melted['Table'] == 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "print(f'This Took {round((end_time - start_time)/60, 2)} minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write to Excel Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1164,
   "metadata": {},
   "outputs": [],
   "source": [
    "if write_to_excel == True:\n",
    "    \n",
    "    date = datetime.now().strftime(\"%m%d%Y%H%M\")\n",
    "\n",
    "    # Write DataFrames to Excel with different sheets\n",
    "    with pd.ExcelWriter(rf\"C:\\Users\\Administrator\\Downloads\\SeatingArrangement_{date}.xlsx\") as writer:\n",
    "        summary_df.to_excel(writer, sheet_name='SummaryStats', index=True)\n",
    "        table_frameworks_df.to_excel(writer, sheet_name='TableFramework', index=True)\n",
    "        ratio_counts_df.to_excel(writer, sheet_name='RatioCounts', index=True)\n",
    "        FA_counts_df.to_excel(writer, sheet_name='FACounts', index=True)\n",
    "        meeting_assignments_df.to_excel(writer, sheet_name='SeatingArrangement', index=True)\n",
    "        # meeting_assignments_df_melted.to_excel(writer, sheet_name='AllSessionTables', index=True)\n",
    "        raw_prefs_A_df.to_excel(writer, sheet_name = 'PrefsForAllocators', index = True)\n",
    "        raw_prefs_F_df.to_excel(writer, sheet_name = 'PrefsForManagers', index = True)\n",
    "        satisfied_prefs_df.to_excel(writer, sheet_name='SatisfiedPrefs', index=True)\n",
    "        unsatisfied_prefs_df.to_excel(writer, sheet_name='UnsatisfiedPrefs', index=True)\n",
    "        pair_counts_matrix.to_excel(writer, sheet_name='PairCountsMatrix', index=True)\n",
    "        pair_counts_matrix_no8.to_excel(writer, sheet_name='PairCountsMatrix (no Lunch)', index=True)\n",
    "        pair_counts_matrix_main.to_excel(writer, sheet_name='PairCountsMatrix (no Lunch MA)', index=True)\n",
    "        allocator_no_prefs_raw_df.to_excel(writer, sheet_name='AllocatorNoPrefs(Raw)', index=True)\n",
    "        allocator_no_prefs_satisfied_df.to_excel(writer, sheet_name='AllocatorNoPrefs(Satisfied)', index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to DB \n",
    "This code does not work since this is a project built on sample data and not affiliated with any true Data Source. However, I still wanted to write code to show how I would write this into a Database table if need be. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OCDB Connection \n",
    "\n",
    "logins_username = \"\"\n",
    "\n",
    "logins_password = \"\"\n",
    "\n",
    "server =  \"\"\n",
    "\n",
    "# Choose Database\n",
    "database= ''\n",
    "\n",
    "## Create Engine and Connection to the Database\n",
    "engine = db.create_engine(\n",
    "    'mssql+pyodbc://'+logins_username+':'+logins_password+'@'+server+'/'+database+'?driver=SQL Server', \n",
    "    use_setinputsizes=False) # This argument got rid of the Error\n",
    "\n",
    "# Find all tables in the db \n",
    "cnxn = pyodbc.connect('DRIVER={SQL Server};SERVER='+server+';DATABASE='+database+';UID='+logins_username+';PWD='+ logins_password)\n",
    "tables = pd.read_sql(\"select * from INFORMATION_SCHEMA.TABLES\", cnxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set table name\n",
    "table_name = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asset Class Session\n",
    "string_weights_asset_session = f'weight_max_asset_class_match1_asset = {weight_max_asset_class_match1_asset}, weight_max_asset_class_match2_asset = {weight_max_asset_class_match2_asset}, weight_min_allocator_no_prefs_asset = {weight_min_allocator_no_prefs_asset}'\n",
    "\n",
    "# Manager Allocator Only Session\n",
    "string_weights_MA_session= f'weight_max_institution_matches_MA = {weight_max_institution_matches_MA}, weight_max_fund_asset_matches_MA = {weight_max_fund_asset_matches_MA}'\n",
    "\n",
    "# Dive Deeper Sessions\n",
    "string_weights_dd_session= f'weight_max_fund_asset_matches_dd = {weight_max_fund_asset_matches_dd}, weight_max_mutual_prefs_dd = {weight_max_mutual_prefs_dd}, weight_max_allocator_prefs_dd = {weight_max_allocator_prefs_dd}, weight_max_fund_prefs_dd = {weight_max_fund_prefs_dd}, weight_min_allocator_no_prefs_dd = {weight_min_allocator_no_prefs_dd}'\n",
    "\n",
    "# Main Sessions \n",
    "string_weights_main_session= f'weight_max_mutual_prefs = {weight_max_mutual_prefs}, weight_max_allocator_prefs = {weight_max_allocator_prefs}, weight_max_fund_prefs = {weight_max_fund_prefs}, weight_min_allocator_no_prefs = {weight_min_allocator_no_prefs}, weight_max_aum_matches = {weight_max_aum_matches}, weight_min_aum_no_matches  = {weight_min_aum_no_matches}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tables = pd.read_sql(\"select * from INFORMATION_SCHEMA.TABLES\", cnxn)\n",
    "# tables[tables['TABLE_NAME'] == table_name]\n",
    "\n",
    "# Subset to only needed fields \n",
    "write_meeting_assignments_df = meeting_assignments_df.copy()\n",
    "\n",
    "# Add column with date time\n",
    "write_meeting_assignments_df['Run_Date'] = datetime.now()\n",
    "\n",
    "# Add column with Run time - want to look at how this changes as the number of meetings increases \n",
    "write_meeting_assignments_df['Run_Time(min)'] = round(((end_time - start_time)/60),2)\n",
    "\n",
    "# Add column with weights for each consideration \n",
    "write_meeting_assignments_df['Parameters (Asset Class)'] = string_weights_asset_session\n",
    "write_meeting_assignments_df['Parameters (Fund/Allocator Only)'] = string_weights_MA_session\n",
    "write_meeting_assignments_df['Parameters (Dive Deeper)'] = string_weights_dd_session\n",
    "write_meeting_assignments_df['Parameters (Main)'] = string_weights_main_session\n",
    "\n",
    "write_meeting_assignments_df = write_meeting_assignments_df.reset_index() \n",
    "\n",
    "write_meeting_assignments_df = write_meeting_assignments_df.fillna('-')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# CHECKS IF TABLE IS THERE - if not, create it using above function.  \n",
    "\n",
    "if table_name in pd.read_sql(\"select * from INFORMATION_SCHEMA.TABLES\", cnxn)['TABLE_NAME'].tolist():\n",
    "    # TRUNCATE TABLE \n",
    "    # cnxn.execute(f\"TRUNCATE TABLE {table_name}\")\n",
    "    # print(f\"The contents of table '{table_name}' have been deleted.\")\n",
    "\n",
    "    # DROP TABLE \n",
    "    # cnxn.execute(f\"DROP TABLE {table_name}\")\n",
    "    # print(f\"{table_name} has been deleted.\")\n",
    "\n",
    "    # APPEND to Table\n",
    "    print('The table is in the DB!')\n",
    "else:\n",
    "    print(f\"Table '{table_name}' does not exist, creating!\")\n",
    "    create_database_table(table_name,'write_meeting_assignments_df', write_meeting_assignments_df.columns, engine)## GOOD TO GO\n",
    "\n",
    "cnxn.commit()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# POPULATE TABLE\n",
    "# check after the possible creation of the table above if the table is there\n",
    "tables = pd.read_sql(\"select * from INFORMATION_SCHEMA.TABLES\", cnxn)\n",
    "if table_name in tables['TABLE_NAME'].tolist():\n",
    "    print('Table found in table names')\n",
    "\n",
    "## Check if table exists and is empty - if so populate it ##\n",
    "if pd.read_sql_query(f\"SELECT OBJECT_ID('{table_name}') AS obj_id\", cnxn)['obj_id'][0] is None:\n",
    "    print('ERROR: Table does not exist - check previous code for Table Creation')\n",
    "elif pd.read_sql_query(f\"SELECT COUNT(*) AS count FROM {table_name}\", cnxn)['count'][0] != 0:\n",
    "    print('Table is not empty - Appending data')\n",
    "    write_meeting_assignments_df.to_sql(table_name, con=engine, if_exists='append', index=False)\n",
    "else:\n",
    "    # If table exists and is empty, write the DataFrame to the new SQL table using to_sql()\n",
    "    print(table_name, 'Table exists and is empty - populating :)')\n",
    "    write_meeting_assignments_df.to_sql(table_name, con=engine, if_exists='append', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
